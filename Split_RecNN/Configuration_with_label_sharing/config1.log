num_users: 3153
num_items: 4807
num_product_groups: 10
num_color_groups: 48
num_index_name: 7
{'sales_domain': SalesNN(
  (user_embedding_layer): Embedding(3153, 32)
  (item_embedding_layer): Embedding(4807, 64)
), 'customer_domain': CustomersNN(
  (relu): LeakyReLU(negative_slope=0.01)
  (encoder): Sequential(
    (0): Linear(in_features=2, out_features=4, bias=True)
  )
), 'product_domain': ProductsNN(
  (product_group_embedding_layer): Embedding(10, 5)
  (color_group_embedding_layer): Embedding(48, 16)
  (index_name_embedding_layer): Embedding(7, 3)
), 'server': GovernanceNN(
  (relu): LeakyReLU(negative_slope=0.01)
  (decoder): Sequential(
    (0): Linear(in_features=124, out_features=256, bias=True)
    (1): Linear(in_features=256, out_features=128, bias=True)
    (2): Linear(in_features=128, out_features=1, bias=True)
  )
)}
Epoch 0 - Training loss: 1.04466712474823
Epoch 1 - Training loss: 0.5728796720504761
Epoch 2 - Training loss: 0.33706116676330566
Epoch 3 - Training loss: 0.232522115111351
Epoch 4 - Training loss: 0.17846405506134033
Epoch 5 - Training loss: 0.1467956006526947
Epoch 6 - Training loss: 0.12417841702699661
Epoch 7 - Training loss: 0.1104859709739685
Epoch 8 - Training loss: 0.10162702202796936
Epoch 9 - Training loss: 0.09851697832345963
Epoch 10 - Training loss: 0.08698423951864243
Epoch 11 - Training loss: 0.08092835545539856
Epoch 12 - Training loss: 0.07174326479434967
Epoch 13 - Training loss: 0.06813875585794449
Epoch 14 - Training loss: 0.05810071527957916
Epoch 15 - Training loss: 0.05336571857333183
Epoch 16 - Training loss: 0.05624906346201897
Epoch 17 - Training loss: 0.04605778679251671
Epoch 18 - Training loss: 0.04237857460975647
Epoch 19 - Training loss: 0.040149759501218796
Epoch 20 - Training loss: 0.03534211590886116
Epoch 21 - Training loss: 0.03550766780972481
Epoch 22 - Training loss: 0.03559873253107071
Epoch 23 - Training loss: 0.029834896326065063
Epoch 24 - Training loss: 0.03363223373889923
Epoch 25 - Training loss: 0.03162812814116478
Epoch 26 - Training loss: 0.027468366548419
Epoch 27 - Training loss: 0.025206170976161957
Epoch 28 - Training loss: 0.030489400029182434
Epoch 29 - Training loss: 0.02630995213985443
Epoch 30 - Training loss: 0.02718758024275303
Epoch 31 - Training loss: 0.03009663335978985
Epoch 32 - Training loss: 0.024296211078763008
Epoch 33 - Training loss: 0.02199750579893589
Epoch 34 - Training loss: 0.025940828025341034
Epoch 35 - Training loss: 0.02228391170501709
Epoch 36 - Training loss: 0.01672852225601673
Epoch 37 - Training loss: 0.02446047030389309
Epoch 38 - Training loss: 0.022506678476929665
Epoch 39 - Training loss: 0.021118737757205963
Epoch 40 - Training loss: 0.019242284819483757
Epoch 41 - Training loss: 0.01954691857099533
Epoch 42 - Training loss: 0.016073543578386307
Epoch 43 - Training loss: 0.016408881172537804
Epoch 44 - Training loss: 0.016980772837996483
Epoch 45 - Training loss: 0.019924234598875046
Epoch 46 - Training loss: 0.017780225723981857
Epoch 47 - Training loss: 0.013221428729593754
Epoch 48 - Training loss: 0.010355371981859207
Epoch 49 - Training loss: 0.00883415061980486
Epoch 50 - Training loss: 0.01779700629413128
Epoch 51 - Training loss: 0.012891716323792934
Epoch 52 - Training loss: 0.01475472841411829
Epoch 53 - Training loss: 0.016694504767656326
Epoch 54 - Training loss: 0.010378330014646053
Epoch 55 - Training loss: 0.009236582554876804
Epoch 56 - Training loss: 0.008274970576167107
Epoch 57 - Training loss: 0.01185038685798645
Epoch 58 - Training loss: 0.00868490245193243
Epoch 59 - Training loss: 0.008167820051312447
Epoch 60 - Training loss: 0.009676779620349407
Epoch 61 - Training loss: 0.008138337172567844
Epoch 62 - Training loss: 0.00897131022065878
Epoch 63 - Training loss: 0.008992133662104607
Epoch 64 - Training loss: 0.0073562501929700375
Epoch 65 - Training loss: 0.009841158986091614
Epoch 66 - Training loss: 0.005935829132795334
Epoch 67 - Training loss: 0.013888918794691563
Epoch 68 - Training loss: 0.010351909324526787
Epoch 69 - Training loss: 0.003272981382906437
Epoch 70 - Training loss: 0.008890478871762753
Epoch 71 - Training loss: 0.006958611309528351
Epoch 72 - Training loss: 0.0031938618049025536
Epoch 73 - Training loss: 0.0038182490970939398
Epoch 74 - Training loss: 0.0034523867070674896
Epoch 75 - Training loss: 0.006803619209676981
Epoch 76 - Training loss: 0.007861476391553879
Epoch 77 - Training loss: 0.004742583259940147
Epoch 78 - Training loss: 0.006241513881832361
Epoch 79 - Training loss: 0.0024838061071932316
Epoch 80 - Training loss: 0.002280227607116103
Epoch 81 - Training loss: 0.008275897242128849
Epoch 82 - Training loss: 0.007193384692072868
Epoch 83 - Training loss: 0.005380900111049414
Epoch 84 - Training loss: 0.0022677979432046413
Epoch 85 - Training loss: 0.001417335239239037
Epoch 86 - Training loss: 0.0005712461424991488
Epoch 87 - Training loss: 0.007413939107209444
Epoch 88 - Training loss: 0.009172425605356693
Epoch 89 - Training loss: 0.0037223228719085455
Epoch 90 - Training loss: 0.0024561318568885326
Epoch 91 - Training loss: 0.0037700932007282972
Epoch 92 - Training loss: 0.008290338329970837
Epoch 93 - Training loss: 0.003519990248605609
Epoch 94 - Training loss: 0.00335481739602983
Epoch 95 - Training loss: 0.0067122322507202625
Epoch 96 - Training loss: 0.0024411899503320456
Epoch 97 - Training loss: 0.002763530006632209
Epoch 98 - Training loss: 0.006561957765370607
Epoch 99 - Training loss: 0.0052967979572713375
Epoch 100 - Training loss: 0.005213055294007063
Epoch 101 - Training loss: 0.0021305696573108435
Epoch 102 - Training loss: 0.003269009292125702
Epoch 103 - Training loss: 0.008444641716778278
Epoch 104 - Training loss: 0.010251362808048725
Epoch 105 - Training loss: 0.003752819960936904
Epoch 106 - Training loss: 0.001015119138173759
Epoch 107 - Training loss: 0.008083500899374485
Epoch 108 - Training loss: 0.004801088944077492
Epoch 109 - Training loss: 0.0011354942107573152
Epoch 110 - Training loss: 0.00039511171053163707
Epoch 111 - Training loss: 0.0002770968421828002
Epoch 112 - Training loss: 0.008860708214342594
Epoch 113 - Training loss: 0.009786602109670639
Epoch 114 - Training loss: 0.003704533213749528
Epoch 115 - Training loss: 0.0010407957015559077
Epoch 116 - Training loss: 0.0006231743609532714
Epoch 117 - Training loss: 0.005424668546766043
Epoch 118 - Training loss: 0.00819814670830965
Epoch 119 - Training loss: 0.008464825339615345
Epoch 120 - Training loss: 0.0038083475083112717
Epoch 121 - Training loss: 0.0015563666820526123
Epoch 122 - Training loss: 0.003767063608393073
Epoch 123 - Training loss: 0.0031776565592736006
Epoch 124 - Training loss: 0.0008493903442285955
Epoch 125 - Training loss: 0.002258030930534005
Epoch 126 - Training loss: 0.0070540704764425755
Epoch 127 - Training loss: 0.006542474031448364
Epoch 128 - Training loss: 0.00575149105861783
Epoch 129 - Training loss: 0.003207593457773328
Epoch 130 - Training loss: 0.002093152841553092
Epoch 131 - Training loss: 0.0018380549736320972
Epoch 132 - Training loss: 0.0009833324002102017
Epoch 133 - Training loss: 0.0004894984303973615
Epoch 134 - Training loss: 7.62766576372087e-05
Epoch 135 - Training loss: 0.007599459495395422
Epoch 136 - Training loss: 0.0062570287846028805
Epoch 137 - Training loss: 0.0014036190696060658
Epoch 138 - Training loss: 0.006846947129815817
Epoch 139 - Training loss: 0.00320319808088243
Epoch 140 - Training loss: 0.0010186104336753488
Epoch 141 - Training loss: 0.009423415176570415
Epoch 142 - Training loss: 0.00537560461089015
Epoch 143 - Training loss: 0.005955429747700691
Epoch 144 - Training loss: 0.002712156856432557
Epoch 145 - Training loss: 0.00111570383887738
Epoch 146 - Training loss: 0.0003438130661379546
Epoch 147 - Training loss: 0.0004848715616390109
Epoch 148 - Training loss: 0.0036332495510578156
Epoch 149 - Training loss: 0.013101216405630112
Epoch 150 - Training loss: 0.003908598329871893
Epoch 151 - Training loss: 0.0023246926721185446
Epoch 152 - Training loss: 0.002851993776857853
ERROR:root:Internal Python error in the inspect module.
Below is the traceback from this internal error.

Traceback (most recent call last):
  File "/home/haoyuan/.conda/envs/datamesh-dev/lib/python3.7/site-packages/syft/frameworks/torch/tensors/interpreters/native.py", line 337, in handle_func_command
    cmd, args_, kwargs_, return_args_type=True
  File "/home/haoyuan/.conda/envs/datamesh-dev/lib/python3.7/site-packages/syft/generic/frameworks/hook/hook_args.py", line 157, in unwrap_args_from_function
    new_args = hook_args(args_)
  File "/home/haoyuan/.conda/envs/datamesh-dev/lib/python3.7/site-packages/syft/generic/frameworks/hook/hook_args.py", line 356, in <lambda>
    return lambda x: f(lambdas, x)
  File "/home/haoyuan/.conda/envs/datamesh-dev/lib/python3.7/site-packages/syft/generic/frameworks/hook/hook_args.py", line 551, in five_fold
    lambdas[0](args_[0], **kwargs),
  File "/home/haoyuan/.conda/envs/datamesh-dev/lib/python3.7/site-packages/syft/generic/frameworks/hook/hook_args.py", line 331, in <lambda>
    else lambda i: forward_func[type(i)](i)
  File "/home/haoyuan/.conda/envs/datamesh-dev/lib/python3.7/site-packages/syft/frameworks/torch/hook/hook_args.py", line 27, in <lambda>
    else (_ for _ in ()).throw(PureFrameworkTensorFoundError),
  File "/home/haoyuan/.conda/envs/datamesh-dev/lib/python3.7/site-packages/syft/frameworks/torch/hook/hook_args.py", line 27, in <genexpr>
    else (_ for _ in ()).throw(PureFrameworkTensorFoundError),
syft.exceptions.PureFrameworkTensorFoundError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/haoyuan/.conda/envs/datamesh-dev/lib/python3.7/site-packages/IPython/core/interactiveshell.py", line 3457, in run_code
    exec(code_obj, self.user_global_ns, self.user_ns)
  File "/tmp/ipykernel_156516/504512500.py", line 12, in <module>
    loss = train(data_ptr, labels, splitnn)
  File "/tmp/ipykernel_156516/4013794522.py", line 115, in train
    pred = splitNN.forward(x)
  File "/tmp/ipykernel_156516/4013794522.py", line 72, in forward
    client_output[owner.id] = self.models[owner.id](data_pointer[owner.id][0], data_pointer[owner.id][1], data_pointer[owner.id][2])
  File "/home/haoyuan/.conda/envs/datamesh-dev/lib/python3.7/site-packages/torch/nn/modules/module.py", line 532, in __call__
    result = self.forward(*input, **kwargs)
  File "/tmp/ipykernel_156516/3475812656.py", line 95, in forward
    color_group_embedding = self.color_group_embedding_layer(color_groups)
  File "/home/haoyuan/.conda/envs/datamesh-dev/lib/python3.7/site-packages/torch/nn/modules/module.py", line 532, in __call__
    result = self.forward(*input, **kwargs)
  File "/home/haoyuan/.conda/envs/datamesh-dev/lib/python3.7/site-packages/torch/nn/modules/sparse.py", line 114, in forward
    self.norm_type, self.scale_grad_by_freq, self.sparse)
  File "/home/haoyuan/.conda/envs/datamesh-dev/lib/python3.7/site-packages/syft/generic/frameworks/hook/hook.py", line 335, in overloaded_func
    response = handle_func_command(command)
  File "/home/haoyuan/.conda/envs/datamesh-dev/lib/python3.7/site-packages/syft/frameworks/torch/tensors/interpreters/native.py", line 356, in handle_func_command
    response = new_type.handle_func_command(new_command)
  File "/home/haoyuan/.conda/envs/datamesh-dev/lib/python3.7/site-packages/syft/generic/pointers/object_pointer.py", line 211, in handle_func_command
    response = owner.send_command(location, cmd_name=cmd, args_=args_, kwargs_=kwargs_)
  File "/home/haoyuan/.conda/envs/datamesh-dev/lib/python3.7/site-packages/syft/workers/base.py", line 525, in send_command
    ret_val = self.send_msg(message, location=recipient)
  File "/home/haoyuan/.conda/envs/datamesh-dev/lib/python3.7/site-packages/syft/workers/base.py", line 316, in send_msg
    bin_response = self._send_msg(bin_message, location)
  File "/home/haoyuan/.conda/envs/datamesh-dev/lib/python3.7/site-packages/syft/workers/virtual.py", line 12, in _send_msg
    return location._recv_msg(message)
  File "/home/haoyuan/.conda/envs/datamesh-dev/lib/python3.7/site-packages/syft/workers/virtual.py", line 22, in _recv_msg
    return self.recv_msg(message)
  File "/home/haoyuan/.conda/envs/datamesh-dev/lib/python3.7/site-packages/syft/workers/base.py", line 356, in recv_msg
    response = handler.handle(msg)
  File "/home/haoyuan/.conda/envs/datamesh-dev/lib/python3.7/site-packages/syft/generic/abstract/message_handler.py", line 20, in handle
    return self.routing_table[type(msg)](msg)
  File "/home/haoyuan/.conda/envs/datamesh-dev/lib/python3.7/site-packages/syft/workers/message_handler.py", line 55, in execute_tensor_command
    return self.execute_computation_action(cmd.action)
  File "/home/haoyuan/.conda/envs/datamesh-dev/lib/python3.7/site-packages/syft/workers/message_handler.py", line 118, in execute_computation_action
    response = command(*args_, **kwargs_)
  File "/home/haoyuan/.conda/envs/datamesh-dev/lib/python3.7/site-packages/syft/generic/frameworks/hook/hook.py", line 335, in overloaded_func
    response = handle_func_command(command)
  File "/home/haoyuan/.conda/envs/datamesh-dev/lib/python3.7/site-packages/syft/frameworks/torch/tensors/interpreters/native.py", line 380, in handle_func_command
    response = cls._get_response(cmd, args_, kwargs_)
  File "/home/haoyuan/.conda/envs/datamesh-dev/lib/python3.7/site-packages/syft/frameworks/torch/tensors/interpreters/native.py", line 414, in _get_response
    response = command_method(*args_, **kwargs_)
  File "/home/haoyuan/.conda/envs/datamesh-dev/lib/python3.7/site-packages/torch/nn/functional.py", line 1484, in embedding
    return torch.embedding(weight, input, padding_idx, scale_grad_by_freq, sparse)
  File "/home/haoyuan/.conda/envs/datamesh-dev/lib/python3.7/site-packages/syft/generic/frameworks/hook/hook.py", line 335, in overloaded_func
    response = handle_func_command(command)
  File "/home/haoyuan/.conda/envs/datamesh-dev/lib/python3.7/site-packages/syft/frameworks/torch/tensors/interpreters/native.py", line 380, in handle_func_command
    response = cls._get_response(cmd, args_, kwargs_)
  File "/home/haoyuan/.conda/envs/datamesh-dev/lib/python3.7/site-packages/syft/frameworks/torch/tensors/interpreters/native.py", line 414, in _get_response
    response = command_method(*args_, **kwargs_)
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/haoyuan/.conda/envs/datamesh-dev/lib/python3.7/site-packages/IPython/core/interactiveshell.py", line 2077, in showtraceback
    stb = value._render_traceback_()
AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/haoyuan/.conda/envs/datamesh-dev/lib/python3.7/site-packages/IPython/core/ultratb.py", line 1101, in get_records
    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)
  File "/home/haoyuan/.conda/envs/datamesh-dev/lib/python3.7/site-packages/IPython/core/ultratb.py", line 248, in wrapped
    return f(*args, **kwargs)
  File "/home/haoyuan/.conda/envs/datamesh-dev/lib/python3.7/site-packages/IPython/core/ultratb.py", line 281, in _fixed_getinnerframes
    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))
  File "/home/haoyuan/.conda/envs/datamesh-dev/lib/python3.7/inspect.py", line 1502, in getinnerframes
    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)
  File "/home/haoyuan/.conda/envs/datamesh-dev/lib/python3.7/inspect.py", line 1460, in getframeinfo
    filename = getsourcefile(frame) or getfile(frame)
  File "/home/haoyuan/.conda/envs/datamesh-dev/lib/python3.7/inspect.py", line 696, in getsourcefile
    if getattr(getmodule(object, filename), '__loader__', None) is not None:
  File "/home/haoyuan/.conda/envs/datamesh-dev/lib/python3.7/inspect.py", line 739, in getmodule
    f = getabsfile(module)
  File "/home/haoyuan/.conda/envs/datamesh-dev/lib/python3.7/inspect.py", line 708, in getabsfile
    _filename = getsourcefile(object) or getfile(object)
  File "/home/haoyuan/.conda/envs/datamesh-dev/lib/python3.7/inspect.py", line 693, in getsourcefile
    if os.path.exists(filename):
  File "/home/haoyuan/.conda/envs/datamesh-dev/lib/python3.7/genericpath.py", line 19, in exists
    os.stat(path)
KeyboardInterrupt
num_users: 3153
num_items: 4807
num_product_groups: 10
num_color_groups: 48
WARNING:root:Torch was already hooked... skipping hooking process
