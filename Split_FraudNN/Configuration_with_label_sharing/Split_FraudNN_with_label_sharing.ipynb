{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "parent_dir = str(Path.cwd().parent)\n",
    "if parent_dir not in sys.path:\n",
    "    sys.path.append(parent_dir)\n",
    "\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import syft as sy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "np.random.seed(666)\n",
    "from Distributed_CreditCard_Data import CreditCardDataLoader, Distributed_CreditCard, binary_acc\n",
    "\n",
    "dataDir = Path.cwd().parent.parent/'CreditCard/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import logging\n",
    "\n",
    "# preserve training log\n",
    "so = open(\"config1.log\", 'w', 10)\n",
    "sys.stdout.echo = so\n",
    "sys.stderr.echo = so\n",
    "\n",
    "get_ipython().log.handlers[0].stream = so\n",
    "get_ipython().log.setLevel(logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DigitalNN(nn.Module):\n",
    "    \"\"\" Partial model for digital transaction domain\n",
    "    Args:\n",
    "        input_size (int): number of features in digital transaction domain\n",
    "        digital_transaction_intput (tensor): input size of digital transaction domain\n",
    "    \n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "            self, \n",
    "            input_size: int,\n",
    "            hidden_size: int = 32,\n",
    "            output_size: int = 16,\n",
    "        ):\n",
    "        super().__init__()\n",
    "\n",
    "        self.layers_stack = nn.Sequential(\n",
    "            nn.Linear(input_size, hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(hidden_size),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(hidden_size, output_size),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        \n",
    "    def forward(self, digital_input):\n",
    "        \n",
    "        for layer in self.layers_stack:\n",
    "            digital_input = layer(digital_input)\n",
    "        \n",
    "        return digital_input\n",
    "    \n",
    "    # save weights of partial model on remote worker\n",
    "    def get_weights(self):\n",
    "        return self.state_dict()\n",
    "\n",
    "class RetailNN(nn.Module):\n",
    "    \"\"\" Partial model for retail transaction domain\n",
    "\n",
    "    Args:\n",
    "        input_size (int): number of features in retail transaction domain\n",
    "        retail_transaction_intput (tensor): input size of retail transaction domain\n",
    "    \n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "            self, \n",
    "            input_size: int,\n",
    "            hidden_size: int = 32,\n",
    "            output_size: int = 16,\n",
    "        ):\n",
    "        super().__init__()\n",
    "\n",
    "        self.layers_stack = nn.Sequential(\n",
    "            nn.Linear(input_size, hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(hidden_size),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(hidden_size, output_size),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        \n",
    "    def forward(self, retail_input):\n",
    "        \n",
    "        for layer in self.layers_stack:\n",
    "            retail_input = layer(retail_input)\n",
    "        \n",
    "        return retail_input\n",
    "    \n",
    "    # save weights of partial model on remote worker\n",
    "    def get_weights(self):\n",
    "        return self.state_dict()\n",
    "    \n",
    "class FraudPrevNN(nn.Module):\n",
    "    \"\"\" Partial model for fraud prevention domain\n",
    "\n",
    "    Args:\n",
    "        input_size (int): number of features in fraud prevention domain\n",
    "        fraud_prev_intput (tensor): input size of fraud prevention domain\n",
    "    \n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "            self, \n",
    "            input_size: int,\n",
    "            hidden_size: int = 32,\n",
    "            output_size: int = 16,\n",
    "        ):\n",
    "        super().__init__()\n",
    "\n",
    "        self.layers_stack = nn.Sequential(\n",
    "            nn.Linear(input_size, hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(hidden_size),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(hidden_size, output_size),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        \n",
    "    def forward(self, fraud_prev_input):\n",
    "        \n",
    "        for layer in self.layers_stack:\n",
    "            fraud_prev_input = layer(fraud_prev_input)\n",
    "        \n",
    "        return fraud_prev_input\n",
    "    \n",
    "    # save weights of partial model on remote worker\n",
    "    def get_weights(self):\n",
    "        return self.state_dict()\n",
    "\n",
    "class GovernanceNN(nn.Module):\n",
    "    \"\"\"Partial model for governance side\n",
    "    \n",
    "    Args:\n",
    "        input_size (int): number of features in governance side\n",
    "        governance_input (tensor): input size of governance side\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "            self,\n",
    "            input_size: int = 48,\n",
    "            hidden_size: int = 64,\n",
    "            output_size: int = 2,\n",
    "        ):\n",
    "        super().__init__()\n",
    "\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "\n",
    "        self.layers_stack = nn.Sequential(\n",
    "            nn.Linear(input_size, hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(hidden_size),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(hidden_size, hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(hidden_size),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(hidden_size, output_size),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "    def forward(self, governance_input):\n",
    "\n",
    "        for layer in self.layers_stack:\n",
    "            governance_input = layer(governance_input)\n",
    "        return governance_input\n",
    "    \n",
    "    # save weights of partial model on remote worker\n",
    "    def get_weights(self):\n",
    "        return self.state_dict()\n",
    "    \n",
    "class SplitFraudNN(nn.Module):\n",
    "    \"\"\" Split fraud neural network \n",
    "    \n",
    "    Args:\n",
    "        data_pointer (dict): syft data pointer\n",
    "    \"\"\"\n",
    "    def __init__(self, models, optimizers, data_owners, server):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.models = models\n",
    "        self.optimizers = optimizers\n",
    "        self.data_owners = data_owners\n",
    "        self.server = server\n",
    "    \n",
    "    def forward(self, data_pointer):\n",
    "\n",
    "        #individual client's output upto their respective cut layer\n",
    "        client_output = {}\n",
    "\n",
    "        #outputs that is moved to server and subjected to concatenate for server input\n",
    "        remote_output = []\n",
    "\n",
    "        for owner in self.data_owners:\n",
    "            client_output[owner.id] = self.models[owner.id](data_pointer[owner.id])\n",
    "            remote_output.append(client_output[owner.id].move(self.server, requires_grad=True))\n",
    "        \n",
    "        # concatenate the output of individual client's output\n",
    "        server_input = torch.cat(remote_output, dim=1)\n",
    "        # server side make prediction\n",
    "        pred = self.models[\"server\"](server_input)\n",
    "\n",
    "        return pred\n",
    "\n",
    "    def zero_grad(self):\n",
    "        for opt in self.optimizers:\n",
    "            opt.zero_grad()\n",
    "    \n",
    "    def step(self):\n",
    "        for opt in self.optimizers:\n",
    "            opt.step()\n",
    "\n",
    "    def train(self):\n",
    "        for loc in self.models.keys():\n",
    "            self.models[loc].train()\n",
    "    \n",
    "    def eval(self):\n",
    "        for loc in self.models.keys():\n",
    "            self.models[loc].eval()\n",
    "\n",
    "def train(x, target, splitNN):\n",
    "    \n",
    "    splitNN.zero_grads()\n",
    "    pred = splitNN.forward(x)\n",
    "  \n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    loss = criterion(pred, target)\n",
    "    \n",
    "    #Backprop the loss on the end layer\n",
    "    loss.backward()\n",
    "    splitNN.step()\n",
    "    \n",
    "    return loss.detach().get()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "digital_transaction_data = np.load(dataDir/'digital_transaction_train.npy')\n",
    "retail_transaction_data = np.load(dataDir/'retail_transaction_train.npy')\n",
    "fraud_prevention_data = np.load(dataDir/'fraud_prevention_train.npy')\n",
    "labels = np.load(dataDir/'labels_train.npy')\n",
    "\n",
    "train_data = CreditCardDataLoader(digital_transaction_data, retail_transaction_data, fraud_prevention_data, labels)\n",
    "train_loader = DataLoader(train_data, batch_size=256, shuffle=True)\n",
    "\n",
    "# set up virtual workers for SplitFraudNN\n",
    "hook = sy.TorchHook(torch)\n",
    "digital_domain = sy.VirtualWorker(hook, id=\"digital_domain\")\n",
    "retail_domain = sy.VirtualWorker(hook, id=\"retail_domain\")\n",
    "fraud_prevention_domain = sy.VirtualWorker(hook, id=\"fraud_prevention_domain\")\n",
    "server = sy.VirtualWorker(hook, id=\"server\")\n",
    "\n",
    "data_owners = (digital_domain, retail_domain, fraud_prevention_domain)\n",
    "model_locations = [digital_domain, retail_domain, fraud_prevention_domain, server]\n",
    "\n",
    "# set up distributed data loader for SplitFraudNN\n",
    "distributed_trainloader = Distributed_CreditCard(data_owners=data_owners, data_loader=train_loader)\n",
    "\n",
    "# set up models for SplitFraudNN\n",
    "\n",
    "models = {\n",
    "    \"digital_domain\": DigitalNN(input_size=10),\n",
    "    \"retail_domain\": RetailNN(input_size=10),\n",
    "    \"fraud_prevention_domain\": FraudPrevNN(input_size=10),\n",
    "    \"server\": GovernanceNN(input_size=48),\n",
    "}\n",
    "\n",
    "# set up optimizers for SplitFraudNN\n",
    "optimizers = [\n",
    "    optim.Adam(models[owner.id].parameters(), lr=1e-4) for owner in model_locations\n",
    "]\n",
    "\n",
    "for location in model_locations:\n",
    "    models[location.id].send(location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(models)\n",
    "\n",
    "epochs = 100\n",
    "torch.autograd.set_detect_anomaly(True)\n",
    "splitFraudNN = SplitFraudNN(models, optimizers, data_owners, server)\n",
    "\n",
    "for i in tqdm(range(epochs)):\n",
    "    running_loss = 0.0\n",
    "    splitFraudNN.train()\n",
    "    for data_ptr, labels in distributed_trainloader:\n",
    "        labels = labels.send(server)\n",
    "        loss = train(data_ptr, labels, splitFraudNN)\n",
    "        running_loss += loss\n",
    "    else:\n",
    "        print(\"Epoch {} - Training loss: {}\".format(i, running_loss/len(distributed_trainloader)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
