{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.preprocessing import StandardScaler, LabelBinarizer\n",
    "\n",
    "pd.options.mode.chained_assignment = None\n",
    "dataDir = Path.cwd().parent/'Data'\n",
    "np.random.seed(66)\n",
    "\n",
    "articles_usecols = [\"article_id\", \"product_group_name\", \"colour_group_name\", \"index_name\"]\n",
    "customers_usecols = [\"customer_id\", \"club_member_status\", \"age\"]\n",
    "\n",
    "transactions = pd.read_csv(dataDir/'transactions.csv')\n",
    "articles = pd.read_csv(dataDir/'articles.csv', usecols=articles_usecols)\n",
    "customers = pd.read_csv(dataDir/'customers.csv', usecols=customers_usecols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1362281"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(transactions.customer_id.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Preprocessing on articles and customers data\n",
    "    Articles: product_group_name, colour_group_name, index_name\n",
    "    Customers: club_member_status, age\n",
    "\"\"\"\n",
    "\n",
    "articles = articles.loc[articles.product_group_name != \"Unknown\"]\n",
    "articles = articles.loc[articles.colour_group_name != \"Unknown\"]\n",
    "customers.dropna(axis=0, how='any', subset=[\"club_member_status\", \"age\"], inplace=True)\n",
    "# filter out transactions data with articles and customers ID\n",
    "transactions = transactions.loc[transactions['article_id'].isin(articles.article_id.unique())]\n",
    "transactions = transactions.loc[transactions['customer_id'].isin(customers.customer_id.unique())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate customer interactions in transaction data\n",
    "# drop customers that only contain few interactions\n",
    "transactions[\"interaction\"] = 1\n",
    "transactions_temp = transactions.drop_duplicates(subset=[\"customer_id\", \"article_id\"])\n",
    "comb_transactions = transactions_temp[[\"customer_id\", \"interaction\"]].groupby(by=[\"customer_id\"], sort=False, as_index=False).sum([\"interaction\"])\n",
    "comb_transactions = comb_transactions.loc[comb_transactions.interaction >= 5]\n",
    "\n",
    "# randomly select part of the transaction data\n",
    "rand_userIds = np.random.choice(comb_transactions.customer_id.unique(), \n",
    "                                size=int(len(comb_transactions['customer_id'].unique())*0.0005), \n",
    "                                replace=False)\n",
    "\n",
    "transactions = transactions.loc[transactions['customer_id'].isin(rand_userIds)]\n",
    "\n",
    "print('There are {} rows of data from {} users (users with suffication data)'.format(len(transactions), len(rand_userIds)))\n",
    "\n",
    "transactions.drop_duplicates(subset=[\"customer_id\", \"article_id\"], keep=\"first\", inplace=True)\n",
    "\n",
    "# merge transaction data with article and customer data\n",
    "transactions = transactions.merge(customers, how='left', left_on=[\"customer_id\"], right_on=[\"customer_id\"])\n",
    "transactions = transactions.merge(articles, how='left', left_on=[\"article_id\"], right_on=[\"article_id\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_id</th>\n",
       "      <th>article_id</th>\n",
       "      <th>price</th>\n",
       "      <th>sales_channel_id</th>\n",
       "      <th>club_member_status</th>\n",
       "      <th>age</th>\n",
       "      <th>product_group_name</th>\n",
       "      <th>colour_group_name</th>\n",
       "      <th>index_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.288010</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.953100</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.712215</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.717387</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.966737</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.382604</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>-0.966737</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.382604</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>-0.966737</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.382604</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   customer_id  article_id     price  sales_channel_id  club_member_status  \\\n",
       "0            0           0 -0.288010                 0                   0   \n",
       "1            1           1 -0.712215                 0                   0   \n",
       "2            2           2 -0.966737                 1                   0   \n",
       "3            2           3 -0.966737                 1                   0   \n",
       "4            2           4 -0.966737                 1                   0   \n",
       "\n",
       "        age  product_group_name  colour_group_name  index_name  \n",
       "0 -0.953100                   0                  0           0  \n",
       "1 -0.717387                   0                  0           0  \n",
       "2  0.382604                   1                  1           1  \n",
       "3  0.382604                   1                  2           1  \n",
       "4  0.382604                   1                  0           1  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# binarize categorical features club_member_status and sales_channel_id in transaction data\n",
    "lb = LabelBinarizer()\n",
    "transactions.sales_channel_id = lb.fit_transform(transactions.sales_channel_id)\n",
    "transactions.club_member_status = lb.fit_transform(transactions.club_member_status)\n",
    "\n",
    "# standardize numerical features age and price in transaction data\n",
    "std = StandardScaler()\n",
    "transactions[[\"price\", \"age\"]] = std.fit_transform(transactions[[\"price\", \"age\"]])\n",
    "\n",
    "# training set and test set\n",
    "transactions['rank_latest'] = transactions.groupby(['customer_id'])['t_dat'].rank(method='first', ascending=False)\n",
    "\n",
    "train_transactions = transactions[transactions['rank_latest'] != 1]\n",
    "test_transactions = transactions[transactions['rank_latest'] == 1]\n",
    "\n",
    "# drop articles that do not exist in training set\n",
    "test_product_list = list(set(test_transactions.article_id.unique()) & set(train_transactions.article_id.unique()))\n",
    "test_transactions = test_transactions.loc[test_transactions['article_id'].isin(test_product_list)]\n",
    "\n",
    "# drop columns that we no longer need\n",
    "drop_cols = [\"t_dat\", \"interaction\", \"rank_latest\"]\n",
    "train_transactions.drop(labels=drop_cols, axis=1, inplace=True)\n",
    "test_transactions.drop(labels=drop_cols, axis=1, inplace=True)\n",
    "\n",
    "\"\"\"reindex\"\"\"\n",
    "# map string type customer_id to int type\n",
    "customer_mapper = {}\n",
    "customer_keys = train_transactions.customer_id.unique()\n",
    "customer_values = list(range(len(train_transactions.customer_id.unique())))\n",
    "customer_mapper.update(zip(customer_keys, customer_values))\n",
    "\n",
    "# map string type article_id to int type\n",
    "product_mapper = {}\n",
    "product_keys = train_transactions.article_id.unique()\n",
    "product_values = list(range(len(train_transactions.article_id.unique())))\n",
    "product_mapper.update(zip(product_keys, product_values))\n",
    "\n",
    "# map color_group_name to int type\n",
    "color_mapper = {}\n",
    "color_keys = train_transactions.colour_group_name.unique()\n",
    "color_values = list(range(len(train_transactions.colour_group_name.unique())))\n",
    "color_mapper.update(zip(color_keys, color_values))\n",
    "\n",
    "# map color_group_name to int type\n",
    "product_group_mapper = {}\n",
    "product_group_keys = train_transactions.product_group_name.unique()\n",
    "product_group_values = list(range(len(train_transactions.product_group_name.unique())))\n",
    "product_group_mapper.update(zip(product_group_keys, product_group_values))\n",
    "\n",
    "# map index_name to int type\n",
    "index_name_mapper = {}\n",
    "index_name_keys = train_transactions.index_name.unique()\n",
    "index_name_values = list(range(len(train_transactions.index_name.unique())))\n",
    "index_name_mapper.update(zip(index_name_keys, index_name_values))\n",
    "\n",
    "# reindex categorical features based on feature mappers\n",
    "train_transactions[\"customer_id\"] = train_transactions[\"customer_id\"].map(customer_mapper)\n",
    "train_transactions[\"article_id\"] = train_transactions[\"article_id\"].map(product_mapper)\n",
    "train_transactions[\"colour_group_name\"] = train_transactions[\"colour_group_name\"].map(color_mapper)\n",
    "train_transactions[\"product_group_name\"] = train_transactions[\"product_group_name\"].map(product_group_mapper)\n",
    "train_transactions[\"index_name\"] = train_transactions[\"index_name\"].map(index_name_mapper)\n",
    "test_transactions[\"customer_id\"] = test_transactions[\"customer_id\"].map(customer_mapper)\n",
    "test_transactions[\"article_id\"] = test_transactions[\"article_id\"].map(product_mapper)\n",
    "test_transactions[\"colour_group_name\"] = test_transactions[\"colour_group_name\"].map(color_mapper)\n",
    "test_transactions[\"product_group_name\"] = test_transactions[\"product_group_name\"].map(product_group_mapper)\n",
    "test_transactions[\"index_name\"] = test_transactions[\"index_name\"].map(index_name_mapper)\n",
    "\n",
    "# get a list of all articles id\n",
    "all_products_id = train_transactions[\"article_id\"].unique()\n",
    "\n",
    "train_transactions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16450"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_transactions.article_id.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "def sparse_to_tensor(sparse_matrix):\n",
    "    \"\"\"\n",
    "    Transform scipy coo matrix to pytorch sparse tensor\n",
    "    \"\"\"\n",
    "    sparse_matrix = sparse_matrix.tocoo()\n",
    "    values = sparse_matrix.data\n",
    "    indices = (sparse_matrix.row, sparse_matrix.col) # np.vstack\n",
    "    shape = sparse_matrix.shape\n",
    "\n",
    "    i = torch.LongTensor(indices)\n",
    "    v = torch.DoubleTensor(values)\n",
    "    s = torch.Size(shape)\n",
    "\n",
    "    return torch.sparse.DoubleTensor(i, v, s)\n",
    "\n",
    "def sparse_batch_collate(batch): \n",
    "    \"\"\"\n",
    "    Collate function which to transform scipy csr matrix to pytorch sparse tensor\n",
    "    \"\"\"\n",
    "    # batch[0] since it is returned as a one element list\n",
    "\n",
    "    customer_batch, product_batch, targets_batch = batch[0]\n",
    "    \n",
    "    if type(customer_batch[0]) == csr_matrix:\n",
    "        customer_batch = customer_batch.tocoo() # removed vstack\n",
    "        customer_batch = sparse_to_tensor(customer_batch)\n",
    "    else:\n",
    "        customer_batch = torch.DoubleTensor(customer_batch)\n",
    "\n",
    "    if type(product_batch[0]) == csr_matrix:\n",
    "        product_batch = product_batch.tocoo() # removed vstack\n",
    "        product_batch = sparse_to_tensor(product_batch)\n",
    "    else:\n",
    "        product_batch = torch.DoubleTensor(product_batch)\n",
    "    \n",
    "    if type(targets_batch[0]) == csr_matrix:\n",
    "        targets_batch = targets_batch.tocoo() # removed vstack\n",
    "        targets_batch = sparse_to_tensor(targets_batch)\n",
    "    else:\n",
    "        targets_batch = torch.DoubleTensor(targets_batch)\n",
    "    \n",
    "    return customer_batch, product_batch, targets_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article_id</th>\n",
       "      <th>product_group_name</th>\n",
       "      <th>colour_group_name</th>\n",
       "      <th>index_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>108775015</td>\n",
       "      <td>Garment Upper body</td>\n",
       "      <td>Black</td>\n",
       "      <td>Ladieswear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>108775044</td>\n",
       "      <td>Garment Upper body</td>\n",
       "      <td>White</td>\n",
       "      <td>Ladieswear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>108775051</td>\n",
       "      <td>Garment Upper body</td>\n",
       "      <td>Off White</td>\n",
       "      <td>Ladieswear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>110065001</td>\n",
       "      <td>Underwear</td>\n",
       "      <td>Black</td>\n",
       "      <td>Lingeries/Tights</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>110065002</td>\n",
       "      <td>Underwear</td>\n",
       "      <td>White</td>\n",
       "      <td>Lingeries/Tights</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105537</th>\n",
       "      <td>953450001</td>\n",
       "      <td>Socks &amp; Tights</td>\n",
       "      <td>Black</td>\n",
       "      <td>Menswear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105538</th>\n",
       "      <td>953763001</td>\n",
       "      <td>Garment Upper body</td>\n",
       "      <td>Black</td>\n",
       "      <td>Ladieswear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105539</th>\n",
       "      <td>956217002</td>\n",
       "      <td>Garment Full body</td>\n",
       "      <td>Black</td>\n",
       "      <td>Ladieswear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105540</th>\n",
       "      <td>957375001</td>\n",
       "      <td>Accessories</td>\n",
       "      <td>Black</td>\n",
       "      <td>Divided</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105541</th>\n",
       "      <td>959461001</td>\n",
       "      <td>Garment Full body</td>\n",
       "      <td>Off White</td>\n",
       "      <td>Ladieswear</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>105393 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        article_id  product_group_name colour_group_name        index_name\n",
       "0        108775015  Garment Upper body             Black        Ladieswear\n",
       "1        108775044  Garment Upper body             White        Ladieswear\n",
       "2        108775051  Garment Upper body         Off White        Ladieswear\n",
       "3        110065001           Underwear             Black  Lingeries/Tights\n",
       "4        110065002           Underwear             White  Lingeries/Tights\n",
       "...            ...                 ...               ...               ...\n",
       "105537   953450001      Socks & Tights             Black          Menswear\n",
       "105538   953763001  Garment Upper body             Black        Ladieswear\n",
       "105539   956217002   Garment Full body             Black        Ladieswear\n",
       "105540   957375001         Accessories             Black           Divided\n",
       "105541   959461001   Garment Full body         Off White        Ladieswear\n",
       "\n",
       "[105393 rows x 4 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'price'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m~/.conda/envs/datamesh-dev/lib/python3.7/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3360\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3361\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3362\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/datamesh-dev/lib/python3.7/site-packages/pandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/datamesh-dev/lib/python3.7/site-packages/pandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'price'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_1845342/2977940226.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0marticles\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"price\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0marticles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marticle_id\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m108775044\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.conda/envs/datamesh-dev/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3456\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3457\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3458\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3459\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3460\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/datamesh-dev/lib/python3.7/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3361\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3362\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3363\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3365\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_scalar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhasnans\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'price'"
     ]
    }
   ],
   "source": [
    "articles[\"price\"].loc[articles.article_id == 108775044]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HMSaleTrainDataLoader(Dataset):\n",
    "    \"\"\"HMSaleTrainDataLoader Training set of HM sales data\n",
    "\n",
    "    Args:\n",
    "        transactions (pd.DataFrame): Dataframe of transaction records\n",
    "        all_products_id (list): A list contains all product ids\n",
    "    \"\"\"\n",
    "    def __init__(self, transactions, all_products_id, all_customer_product_set):\n",
    "        self.customers, self.products, self.prices, self.sales_channels, \\\n",
    "        self.club_status, self.age_groups, self.product_groups, self.color_groups, \\\n",
    "        self.index_name, self.labels = self.get_dataset(transactions, all_products_id, all_customer_product_set)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.customers)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.customers[idx], self.products[idx], self.prices[idx], self.sales_channels[idx], self.club_status[idx], \\\n",
    "               self.age_groups[idx], self.product_groups[idx], self.color_groups[idx], self.index_name[idx], self.labels[idx]\n",
    "    \n",
    "    def get_dataset(self, transactions, all_products_id, all_customer_product_set):\n",
    "        customers, products, prices, sales_channels, club_status, age_groups, product_groups, color_groups, index_name, labels  = [], [], [], [], [], [], [], [], [], []\n",
    "        \n",
    "        \"\"\"negative sampling\"\"\"\n",
    "        # set up negative:positive ratio as 4:1\n",
    "        negative_samples = 4\n",
    "        customer_product_set = set(zip(transactions[\"customer_id\"], transactions[\"article_id\"], \n",
    "                                       transactions[\"price\"], transactions[\"sales_channel_id\"], \n",
    "                                       transactions[\"club_member_status\"], transactions[\"age\"], \n",
    "                                       transactions[\"product_group_name\"], transactions[\"colour_group_name\"], transactions[\"index_name\"]))\n",
    "\n",
    "        for u, i, price, sale, club, age, product, color, index in tqdm(customer_product_set):\n",
    "            customers.append(u)\n",
    "            products.append(i)\n",
    "            sales_channels.append(sale)\n",
    "            club_status.append(club)\n",
    "            age_groups.append(age)\n",
    "            product_groups.append(product)\n",
    "            color_groups.append(color)\n",
    "            index_name.append(index)\n",
    "            labels.append(1)\n",
    "            for _ in range(negative_samples):\n",
    "                negative_product = np.random.choice(all_products_id)\n",
    "                while (u, negative_product, price, sale, club, age, product, color, index) in all_customer_product_set:\n",
    "                    negative_product = np.random.choice(all_products_id)\n",
    "                customers.append(u)\n",
    "                products.append(negative_product)\n",
    "                prices.append(price)\n",
    "                sales_channels.append(sale)\n",
    "                club_status.append(club)\n",
    "                age_groups.append(age)\n",
    "                product_groups.append(product)\n",
    "                color_groups.append(color)\n",
    "                index_name.append(index)\n",
    "                labels.append(0)\n",
    "        return customers, products, prices, sales_channels, club_status, age_groups, product_groups, color_groups, index_name, torch.tensor(labels)\n",
    "\n",
    "class HMSaleTestDataLoader(Dataset):\n",
    "    \"\"\"HMSaleTestataLoader Test set of HM sales data\n",
    "\n",
    "    Args:\n",
    "        transactions (pd.DataFrame): Dataframe of transaction records\n",
    "        all_products_id (list): A list contains all product ids\n",
    "    \"\"\"\n",
    "    def __init__(self, transactions, all_products_id):\n",
    "        self.customers, self.products, self.prices, self.sales_channels, \\\n",
    "        self.club_status, self.age_groups, self.product_groups, self.color_groups, \\\n",
    "        self.index_name, self.labels = self.get_dataset(transactions, all_products_id)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.customers)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.customers[idx], self.products[idx], self.prices[idx], self.sales_channels[idx], self.club_status[idx], \\\n",
    "               self.age_groups[idx], self.product_groups[idx], self.color_groups[idx], self.index_name[idx], self.labels[idx]\n",
    "    \n",
    "    def get_dataset(self, transactions, all_products_id):\n",
    "        customers, products, prices, sales_channels, club_status, age_groups, product_groups, color_groups, index_name, labels  = [], [], [], [], [], [], [], [], [], []\n",
    "        customer_product_set = set(zip(transactions[\"customer_id\"], transactions[\"article_id\"], \n",
    "                                       transactions[\"price\"], transactions[\"sales_channel_id\"], \n",
    "                                       transactions[\"club_member_status\"], transactions[\"age\"], \n",
    "                                       transactions[\"product_group_name\"], transactions[\"colour_group_name\"], transactions[\"index_name\"]))\n",
    "      \n",
    "        for u, i, price, sale, club, age, product, color, index in tqdm(customer_product_set):\n",
    "            customers.append(u)\n",
    "            products.append(i)\n",
    "            prices.append(price)\n",
    "            sales_channels.append(sale)\n",
    "            club_status.append(club)\n",
    "            age_groups.append(age)\n",
    "            product_groups.append(product)\n",
    "            color_groups.append(color)\n",
    "            index_name.append(index)\n",
    "            labels.append(1)\n",
    "\n",
    "        return torch.tensor(customers), torch.tensor(products), torch.tensor(prices), torch.tensor(sales_channels), torch.tensor(club_status), torch.tensor(age_groups), torch.tensor(product_groups), torch.tensor(color_groups), torch.tensor(index_name), torch.tensor(labels)    \n",
    "\n",
    "def binary_acc(y_pred, y_test):\n",
    "    y_pred_label = torch.softmax(y_pred, dim=1)\n",
    "    _, y_pred_label = torch.max(y_pred_label, dim = 1)\n",
    "    correct_pred = (y_pred_label == y_test).sum()\n",
    "    acc = correct_pred/y_test.shape[0]\n",
    "    return acc  \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NCF(nn.Module):\n",
    "    \"\"\"NCF - Neural Collaborative Filtering proposed by He et al.\n",
    "\n",
    "    Args:\n",
    "        num_users (int): Number of users\n",
    "        num_items (iut): Number of products\n",
    "        num_product_groups (int): Number of product groups\n",
    "        num_color_groups: (int): Number of color groups\n",
    "        num_index_name: (int): Number of index name\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "            self, \n",
    "            num_users: int, \n",
    "            num_items: int,\n",
    "            num_product_groups: int,\n",
    "            num_color_groups: int,\n",
    "            num_index_name: int,\n",
    "            user_embedding_dim: int = 16,\n",
    "            item_embedding_dim: int = 32,\n",
    "            product_group_embedding_dim: int = 8,\n",
    "            color_group_embedding_dim: int = 16,\n",
    "            index_name_embedding_dim: int = 6,\n",
    "            input_size: int = 53,\n",
    "            hidden_size_1: int = 64,\n",
    "            hidden_size_2: int = 128,\n",
    "            output_size: int = 32,\n",
    "            num_classes: int = 2,\n",
    "        ):\n",
    "            super().__init__()\n",
    "            # embedding layers for categorical features and user-item interaction\n",
    "            self.user_embedding_layer = nn.Embedding(num_embeddings=num_users, embedding_dim=user_embedding_dim)\n",
    "            self.item_embedding_layer = nn.Embedding(num_embeddings=num_items, embedding_dim=item_embedding_dim)\n",
    "            self.product_group_embedding_layer = nn.Embedding(num_embeddings=num_product_groups, embedding_dim=product_group_embedding_dim)\n",
    "            self.color_group_embedding_layer = nn.Embedding(num_embeddings=num_color_groups, embedding_dim=color_group_embedding_dim)\n",
    "            self.index_name_embedding_layer = nn.Embedding(num_embeddings=num_index_name, embedding_dim=index_name_embedding_dim)\n",
    "\n",
    "            self.relu = nn.LeakyReLU()\n",
    "            if user_embedding_dim and item_embedding_dim is not None:\n",
    "                in_channels = (\n",
    "                    [input_size] \n",
    "                    + [hidden_size_2]\n",
    "                    + [hidden_size_1]\n",
    "                    + [num_classes]\n",
    "                )\n",
    "            else:\n",
    "                raise ValueError\n",
    "            self.fcs = nn.Sequential(\n",
    "                *[nn.Linear(in_features=in_channels[i], out_features=in_channels[i+1]) for i in range(len(in_channels)-1) if i != len(in_channels)-1]\n",
    "            )\n",
    "            \n",
    "            in_channels_1 = (\n",
    "                [50] \n",
    "                + [hidden_size_2]\n",
    "                + [output_size]\n",
    "            )\n",
    "            in_channels_2 = (\n",
    "                [30] \n",
    "                + [hidden_size_1]\n",
    "                + [16]\n",
    "            )\n",
    "            \n",
    "            self.encoder1 = nn.Sequential(\n",
    "                *[nn.Linear(in_features=in_channels_1[i], out_features=in_channels_1[i+1]) for i in range(len(in_channels_1)-1) if i != len(in_channels_1)-1]\n",
    "            )    \n",
    "            \n",
    "            self.encoder2 = nn.Linear(in_features=2, out_features=5, bias=True)\n",
    "            \n",
    "            self.encoder3 = nn.Sequential(\n",
    "            *[nn.Linear(in_features=in_channels_2[i], out_features=in_channels_2[i+1]) for i in range(len(in_channels_2)-1) if i != len(in_channels_2)-1]\n",
    "            )\n",
    "            \n",
    "    \n",
    "    def forward(self, user_input, item_input, prices, sales_channels, club_status, age_groups, product_groups, color_groups, index_name):\n",
    "\n",
    "        user_embedding = self.user_embedding_layer(user_input)\n",
    "        item_embedding = self.item_embedding_layer(item_input)\n",
    "        product_group_embedding = self.product_group_embedding_layer(product_groups)\n",
    "        color_group_embedding = self.color_group_embedding_layer(color_groups)\n",
    "        index_name_embedding = self.index_name_embedding_layer(index_name)\n",
    "        concat_embedding = torch.cat([user_embedding, item_embedding, product_group_embedding, color_group_embedding, index_name_embedding], dim=-1)\n",
    "        \n",
    "        latent_vec_1 = torch.cat([user_embedding, item_embedding, prices.reshape(-1, 1), sales_channels.reshape(-1, 1)], dim=-1)\n",
    "        latent_vec_1 = self.encoder1(latent_vec_1)\n",
    "\n",
    "        latent_vec_2 = torch.cat([club_status.reshape(-1, 1), age_groups.reshape(-1, 1)], dim=-1)\n",
    "        latent_vec_2 = self.encoder2(latent_vec_2)\n",
    "\n",
    "        latent_vec_3 = torch.cat([product_group_embedding, color_group_embedding, index_name_embedding], dim=-1)\n",
    "        latent_vec_3 = self.encoder3(latent_vec_3)\n",
    "\n",
    "        concat_embedding = torch.cat([latent_vec_1, latent_vec_2, latent_vec_3], dim=-1)\n",
    "        \n",
    "#         concat_input = torch.cat([prices.reshape(-1, 1), sales_channels.reshape(-1, 1), club_status.reshape(-1, 1), age_groups.reshape(-1, 1)], dim=-1)\n",
    "#         concat_embedding = torch.cat([concat_embedding, concat_input], dim=-1)\n",
    "\n",
    "        for fc_layer in self.fcs:\n",
    "            concat_embedding = fc_layer(concat_embedding)\n",
    "            concat_embedding = self.relu(concat_embedding)\n",
    "        #pred = F.softmax(concat_embedding)\n",
    "        return concat_embedding\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_acc(y_pred, y_test):\n",
    "    acc = 0.0\n",
    "    \n",
    "    y_pred_label = torch.softmax(y_pred, dim=1)\n",
    "    _, y_pred_label = torch.max(y_pred_label, dim = 1)\n",
    "    correct_pred = (y_pred_label == y_test).sum()\n",
    "    acc = correct_pred.item()/y_test.shape[0]\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_users: 880\n",
      "num_items: 16450\n",
      "num_product_groups: 13\n",
      "num_color_groups: 49\n",
      "num_index_name: 10\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5fcfedf6287b44e6aed63fabe52ca7d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/26416 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_transactions = pd.read_csv(dataDir/'medium_train.csv')\n",
    "# get a list of all articles id\n",
    "all_products_id = train_transactions[\"article_id\"].unique()\n",
    "customer_product_set = set(zip(transactions[\"customer_id\"], transactions[\"article_id\"], \n",
    "                               transactions[\"price\"], transactions[\"sales_channel_id\"], \n",
    "                               transactions[\"club_member_status\"], transactions[\"age\"], \n",
    "                               transactions[\"product_group_name\"], transactions[\"colour_group_name\"], transactions[\"index_name\"]))\n",
    "\n",
    "# set up hyper-parameters\n",
    "learning_rate = 0.005\n",
    "epoch = 80\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "# device = torch.device(\"cpu\")\n",
    "\n",
    "torch.autograd.set_detect_anomaly(True)\n",
    "\n",
    "# set up dataset for training\n",
    "num_users = len(train_transactions.customer_id.unique())\n",
    "print(\"num_users:\", num_users)\n",
    "num_items = len(all_products_id)\n",
    "print(\"num_items:\", num_items)\n",
    "num_product_groups = len(train_transactions.product_group_name.unique())\n",
    "print(\"num_product_groups:\", num_product_groups)\n",
    "num_color_groups = len(train_transactions.colour_group_name.unique())\n",
    "print(\"num_color_groups:\", num_color_groups)\n",
    "num_index_name = len(train_transactions.index_name.unique())\n",
    "print(\"num_index_name:\", num_index_name)\n",
    "train_data = HMSaleTrainDataLoader(train_transactions, all_products_id, customer_product_set)\n",
    "train_loader = DataLoader(train_data, batch_size=1024, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "132080"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16450"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_products_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_users: 880\n",
      "num_items: 16450\n",
      "num_product_groups: 13\n",
      "num_color_groups: 49\n",
      "num_index_name: 10\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58a6e06b98df498abd359cac39fe0dd5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/26416 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NCF(\n",
      "  (user_embedding_layer): Embedding(880, 16)\n",
      "  (item_embedding_layer): Embedding(16450, 32)\n",
      "  (product_group_embedding_layer): Embedding(13, 8)\n",
      "  (color_group_embedding_layer): Embedding(49, 16)\n",
      "  (index_name_embedding_layer): Embedding(10, 6)\n",
      "  (relu): LeakyReLU(negative_slope=0.01)\n",
      "  (fcs): Sequential(\n",
      "    (0): Linear(in_features=53, out_features=128, bias=True)\n",
      "    (1): Linear(in_features=128, out_features=64, bias=True)\n",
      "    (2): Linear(in_features=64, out_features=2, bias=True)\n",
      "  )\n",
      "  (encoder1): Sequential(\n",
      "    (0): Linear(in_features=50, out_features=128, bias=True)\n",
      "    (1): Linear(in_features=128, out_features=32, bias=True)\n",
      "  )\n",
      "  (encoder2): Linear(in_features=2, out_features=5, bias=True)\n",
      "  (encoder3): Sequential(\n",
      "    (0): Linear(in_features=30, out_features=64, bias=True)\n",
      "    (1): Linear(in_features=64, out_features=16, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "133271315ed140cd96baa6dd552559db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/80 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 000: | Loss: 0.510221 | Acc: 0.7953\n",
      "Epoch 001: | Loss: 0.498899 | Acc: 0.8000\n",
      "Epoch 002: | Loss: 0.484177 | Acc: 0.8012\n",
      "Epoch 003: | Loss: 0.448124 | Acc: 0.8132\n",
      "Epoch 004: | Loss: 0.399691 | Acc: 0.8364\n",
      "Epoch 005: | Loss: 0.349653 | Acc: 0.8611\n",
      "Epoch 006: | Loss: 0.306397 | Acc: 0.8817\n",
      "Epoch 007: | Loss: 0.270558 | Acc: 0.8978\n",
      "Epoch 008: | Loss: 0.239634 | Acc: 0.9107\n",
      "Epoch 009: | Loss: 0.213120 | Acc: 0.9214\n",
      "Epoch 010: | Loss: 0.192285 | Acc: 0.9287\n",
      "Epoch 011: | Loss: 0.170711 | Acc: 0.9365\n",
      "Epoch 012: | Loss: 0.152721 | Acc: 0.9434\n",
      "Epoch 013: | Loss: 0.137393 | Acc: 0.9495\n",
      "Epoch 014: | Loss: 0.121147 | Acc: 0.9545\n",
      "Epoch 015: | Loss: 0.111538 | Acc: 0.9573\n",
      "Epoch 016: | Loss: 0.099764 | Acc: 0.9608\n",
      "Epoch 017: | Loss: 0.091812 | Acc: 0.9632\n",
      "Epoch 018: | Loss: 0.082614 | Acc: 0.9665\n",
      "Epoch 019: | Loss: 0.076051 | Acc: 0.9685\n",
      "Epoch 020: | Loss: 0.070681 | Acc: 0.9700\n",
      "Epoch 021: | Loss: 0.065541 | Acc: 0.9726\n",
      "Epoch 022: | Loss: 0.063165 | Acc: 0.9741\n",
      "Epoch 023: | Loss: 0.057886 | Acc: 0.9764\n",
      "Epoch 024: | Loss: 0.055656 | Acc: 0.9776\n",
      "Epoch 025: | Loss: 0.053162 | Acc: 0.9786\n",
      "Epoch 026: | Loss: 0.047489 | Acc: 0.9814\n",
      "Epoch 027: | Loss: 0.045726 | Acc: 0.9822\n",
      "Epoch 028: | Loss: 0.044407 | Acc: 0.9824\n",
      "Epoch 029: | Loss: 0.041972 | Acc: 0.9843\n",
      "Epoch 030: | Loss: 0.038401 | Acc: 0.9854\n",
      "Epoch 031: | Loss: 0.037334 | Acc: 0.9860\n",
      "Epoch 032: | Loss: 0.034187 | Acc: 0.9872\n",
      "Epoch 033: | Loss: 0.032502 | Acc: 0.9881\n",
      "Epoch 034: | Loss: 0.032298 | Acc: 0.9881\n",
      "Epoch 035: | Loss: 0.030643 | Acc: 0.9886\n",
      "Epoch 036: | Loss: 0.030925 | Acc: 0.9889\n",
      "Epoch 037: | Loss: 0.027231 | Acc: 0.9903\n",
      "Epoch 038: | Loss: 0.026831 | Acc: 0.9904\n",
      "Epoch 039: | Loss: 0.025860 | Acc: 0.9913\n",
      "Epoch 040: | Loss: 0.025879 | Acc: 0.9910\n",
      "Epoch 041: | Loss: 0.026226 | Acc: 0.9908\n",
      "Epoch 042: | Loss: 0.024934 | Acc: 0.9914\n",
      "Epoch 043: | Loss: 0.025469 | Acc: 0.9912\n",
      "Epoch 044: | Loss: 0.025183 | Acc: 0.9915\n",
      "Epoch 045: | Loss: 0.026667 | Acc: 0.9908\n",
      "Epoch 046: | Loss: 0.024420 | Acc: 0.9917\n",
      "Epoch 047: | Loss: 0.020563 | Acc: 0.9929\n",
      "Epoch 048: | Loss: 0.019760 | Acc: 0.9934\n",
      "Epoch 049: | Loss: 0.020761 | Acc: 0.9931\n",
      "Epoch 050: | Loss: 0.019836 | Acc: 0.9936\n",
      "Epoch 051: | Loss: 0.018593 | Acc: 0.9935\n",
      "Epoch 052: | Loss: 0.020395 | Acc: 0.9937\n",
      "Epoch 053: | Loss: 0.019485 | Acc: 0.9938\n",
      "Epoch 054: | Loss: 0.021126 | Acc: 0.9928\n",
      "Epoch 055: | Loss: 0.019348 | Acc: 0.9935\n",
      "Epoch 056: | Loss: 0.018170 | Acc: 0.9940\n",
      "Epoch 057: | Loss: 0.017636 | Acc: 0.9942\n",
      "Epoch 058: | Loss: 0.016397 | Acc: 0.9949\n",
      "Epoch 059: | Loss: 0.017899 | Acc: 0.9942\n",
      "Epoch 060: | Loss: 0.016409 | Acc: 0.9947\n",
      "Epoch 061: | Loss: 0.015973 | Acc: 0.9949\n",
      "Epoch 062: | Loss: 0.018735 | Acc: 0.9941\n",
      "Epoch 063: | Loss: 0.019499 | Acc: 0.9941\n",
      "Epoch 064: | Loss: 0.017386 | Acc: 0.9944\n",
      "Epoch 065: | Loss: 0.016989 | Acc: 0.9948\n",
      "Epoch 066: | Loss: 0.015358 | Acc: 0.9951\n",
      "Epoch 067: | Loss: 0.013065 | Acc: 0.9960\n",
      "Epoch 068: | Loss: 0.013522 | Acc: 0.9956\n",
      "Epoch 069: | Loss: 0.016056 | Acc: 0.9949\n",
      "Epoch 070: | Loss: 0.019380 | Acc: 0.9939\n",
      "Epoch 071: | Loss: 0.018164 | Acc: 0.9945\n",
      "Epoch 072: | Loss: 0.014293 | Acc: 0.9957\n",
      "Epoch 073: | Loss: 0.014491 | Acc: 0.9958\n",
      "Epoch 074: | Loss: 0.015585 | Acc: 0.9952\n",
      "Epoch 075: | Loss: 0.021224 | Acc: 0.9937\n",
      "Epoch 076: | Loss: 0.017038 | Acc: 0.9948\n",
      "Epoch 077: | Loss: 0.015620 | Acc: 0.9954\n",
      "Epoch 078: | Loss: 0.014531 | Acc: 0.9954\n",
      "Epoch 079: | Loss: 0.014303 | Acc: 0.9956\n",
      "\n",
      "Best Accuracy: 0.996\n"
     ]
    }
   ],
   "source": [
    "# initiate model for training\n",
    "model = NCF(num_users=num_users, num_items=num_items, num_product_groups=num_product_groups, num_color_groups=num_color_groups, num_index_name=num_index_name)\n",
    "model.to(device)\n",
    "print(model)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "model.train()\n",
    "best_acc = 0.0\n",
    "for e in tqdm(range(epoch)):\n",
    "    epoch_loss = 0.0\n",
    "    epoch_acc = 0.0\n",
    "    for customer_batch, product_batch, prices_batch, sales_channels_batch, club_status_batch, age_groups_batch, product_groups_batch, color_groups_batch, index_name_batch, label_batch in train_loader:\n",
    "        customer_batch, product_batch, prices_batch, sales_channels_batch, club_status_batch, \\\n",
    "        age_groups_batch, product_groups_batch, color_groups_batch, index_name_batch, label_batch \\\n",
    "        = customer_batch.to(device), product_batch.to(device), prices_batch.to(device), \\\n",
    "        sales_channels_batch.to(device), club_status_batch.to(device), age_groups_batch.to(device), \\\n",
    "        product_groups_batch.to(device), color_groups_batch.to(device), index_name_batch.to(device), label_batch.to(device), \n",
    "        optimizer.zero_grad()\n",
    "        y_pred = model(customer_batch, product_batch, prices_batch.float(), sales_channels_batch.float(), club_status_batch.float(), age_groups_batch.float(), product_groups_batch, color_groups_batch, index_name_batch)\n",
    "        loss = loss_fn(y_pred, label_batch)\n",
    "        acc = binary_acc(y_pred, label_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc += acc\n",
    "        cur_acc = epoch_acc/len(train_loader)\n",
    "    if cur_acc > best_acc:\n",
    "        best_acc = cur_acc\n",
    "        torch.save(model.state_dict(), 'best_model.pt')\n",
    "    print(f'Epoch {e+0:03}: | Loss: {epoch_loss/len(train_loader):.6f} | Acc: {epoch_acc/len(train_loader):.4f}')\n",
    "\n",
    "print(f'\\nBest Accuracy: {best_acc:.3f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hit(gt_items, pred_items):\n",
    "    count = 0\n",
    "    for item in gt_items:\n",
    "        if item in pred_items:\n",
    "            count += 1\n",
    "    return count / len(gt_items)\n",
    "\n",
    "def ndcg(gt_items, pred_items):\n",
    "    dcg, idcg = 0.0, 0.0\n",
    "    for i, item in enumerate(pred_items[:len(gt_items)]):\n",
    "        if item in gt_items:\n",
    "            dcg += 1 / np.log2(i + 2)\n",
    "            idcg += 1 / np.log2(i + 2)\n",
    "    return dcg / idcg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_product_test = set(zip(test_transactions[\"customer_id\"], test_transactions[\"article_id\"], \n",
    "                                test_transactions[\"price\"], test_transactions[\"sales_channel_id\"], \n",
    "                                test_transactions[\"club_member_status\"], test_transactions[\"age\"], \n",
    "                                test_transactions[\"product_group_name\"], test_transactions[\"colour_group_name\"], test_transactions[\"index_name\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dict of all items that are interacted with by each user\n",
    "user_interacted_items = transactions.groupby('customer_id')['article_id'].apply(list).to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da23d8eb5b5c488bbafcaa4f7962c276",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/498 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n",
      "\n",
      "Classification Accuracy on test set: 0.894\n",
      "HR@10: 0.000\n",
      "NDCG@10: 0.000\n"
     ]
    }
   ],
   "source": [
    "# model test\n",
    "\n",
    "test_transactions = pd.read_csv(dataDir/'medium_test.csv')\n",
    "\n",
    "model = NCF(num_users=num_users, num_items=num_items, num_product_groups=num_product_groups, num_color_groups=num_color_groups, num_index_name=num_index_name)\n",
    "test_data = HMSaleTestDataLoader(test_transactions, all_products_id, customer_product_set)\n",
    "test_dataloader = DataLoader(test_data, batch_size=64, shuffle=True)\n",
    "\n",
    "model.load_state_dict(torch.load('best_model.pt'))\n",
    "model.to(device)\n",
    "\n",
    "print(device)\n",
    "\n",
    "model.eval()\n",
    "test_acc = 0.0\n",
    "top_k = 10\n",
    "HR, NDCG = [], []\n",
    "with torch.no_grad():\n",
    "    for customer, product, prices, sales_channels, club_status, age_groups, product_groups, color_groups, index_name, label in tqdm(customer_product_test):\n",
    "        customer, product, prices, sales_channels, club_status, age_groups, product_groups, color_groups, index_name, label \\\n",
    "        = customer.to(device), product.to(device), prices.to(device), sales_channels.to(device), club_status.to(device), \\\n",
    "        age_groups.to(device), product_groups.to(device), color_groups.to(device), index_name.to(device), label.to(device)\n",
    "        \n",
    "        # select 99 products from item set that customer has no interactions\n",
    "        interacted_items = user_interacted_items[customer_batch]\n",
    "        not_interacted_items = set(all_products_id) - set(interacted_items)\n",
    "        selected_not_interacted = list(np.random.choice(list(not_interacted_items), 66))\n",
    "        test_items = selected_not_interacted + [i]\n",
    "        \n",
    "        y_pred = model(torch.tensor([customer]*100), torch.tensor(test_items), prices.float(), sales_channels.float(), club_status.float(), age_groups.float(), product_groups, color_groups, index_name)\n",
    "        acc = binary_acc(y_pred, label)\n",
    "        test_acc += acc\n",
    "        \n",
    "        y_pred_label = torch.softmax(y_pred, dim=1)\n",
    "        _, y_pred_label = torch.max(y_pred_label, dim = 1)\n",
    "        _, indices = torch.topk(y_pred_label, top_k, dim=0)\n",
    "        recommends = torch.take(product_batch, indices).cpu().numpy().tolist()\n",
    "\n",
    "        gt_items = [product.item() for product, label in zip(product_batch, label_batch) if label.item() == 1]\n",
    "        HR.append(hit(gt_items, recommends))\n",
    "        NDCG.append(ndcg(gt_items, recommends))\n",
    "        \n",
    "    test_acc = test_acc / len(test_dataloader)\n",
    "    hr_mean = np.mean(HR)\n",
    "    ndcg_mean = np.mean(NDCG)\n",
    "\n",
    "print(f'\\nClassification Accuracy on test set: {test_acc:.3f}')\n",
    "print(f'HR@{top_k}: {hr_mean:.3f}')\n",
    "print(f'NDCG@{top_k}: {ndcg_mean:.3f}')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[13598, 2269, 7943, 14184, 13396, 3247, 14136, 5368, 15693, 5810]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recommends"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[5218,\n",
       " 16142,\n",
       " 584,\n",
       " 11495,\n",
       " 15576,\n",
       " 7677,\n",
       " 1330,\n",
       " 2378,\n",
       " 3521,\n",
       " 11354,\n",
       " 5796,\n",
       " 1702,\n",
       " 8054,\n",
       " 4111,\n",
       " 8054]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gt_items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12774"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ng_item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[15428, 11222],\n",
       " [16104, 5305],\n",
       " [16425, 12041],\n",
       " [2044, 2866],\n",
       " [14601, 16124],\n",
       " [8933, 8991],\n",
       " [5457, 10828],\n",
       " [15123, 13445],\n",
       " [7441, 16376],\n",
       " [16350, 13129]]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recommends"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2490\n"
     ]
    }
   ],
   "source": [
    "print(len(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HR, NDCG = metrics(model, test_loader, args.top_k, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hit(ng_item, pred_items):\n",
    "    if ng_item in pred_items:\n",
    "        return 1\n",
    "    return 0\n",
    "\n",
    "\n",
    "def ndcg(ng_item, pred_items):\n",
    "    if ng_item in pred_items:\n",
    "        index = pred_items.index(ng_item)\n",
    "        return np.reciprocal(np.log2(index+2))\n",
    "    return 0\n",
    "\n",
    "\n",
    "def metrics(model, test_loader, top_k, device):\n",
    "    HR, NDCG = [], []\n",
    "\n",
    "    for user, item, label in test_loader:\n",
    "        user = user.to(device)\n",
    "        item = item.to(device)\n",
    "\n",
    "        predictions = model(user, item)\n",
    "        _, indices = torch.topk(predictions, top_k)\n",
    "        recommends = torch.take(item, indices).cpu().numpy().tolist()\n",
    "\n",
    "        ng_item = item[0].item() # leave one-out evaluation has only one item per user\n",
    "        HR.append(hit(ng_item, recommends))\n",
    "        NDCG.append(ndcg(ng_item, recommends))\n",
    "\n",
    "    return np.mean(HR), np.mean(NDCG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "7857ada9c2c05e5ee75d334d60fb77cca110ad03375c3b02029444557fa6212d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
