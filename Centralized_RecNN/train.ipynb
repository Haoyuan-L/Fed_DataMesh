{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.preprocessing import StandardScaler, LabelBinarizer\n",
    "\n",
    "pd.options.mode.chained_assignment = None\n",
    "dataDir = Path.cwd().parent.parent.parent/'backup/HM_data'\n",
    "np.random.seed(66)\n",
    "\n",
    "articles_usecols = [\"article_id\", \"product_group_name\", \"colour_group_name\", \"index_name\"]\n",
    "customers_usecols = [\"customer_id\", \"club_member_status\", \"age\"]\n",
    "\n",
    "transactions = pd.read_csv(dataDir/'transactions.csv')\n",
    "articles = pd.read_csv(dataDir/'articles.csv', usecols=articles_usecols)\n",
    "customers = pd.read_csv(dataDir/'customers.csv', usecols=customers_usecols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1342230"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(transactions.customer_id.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Preprocessing on articles and customers data\n",
    "    Articles: product_group_name, colour_group_name, index_name\n",
    "    Customers: club_member_status, age\n",
    "\"\"\"\n",
    "\n",
    "articles = articles.loc[articles.product_group_name != \"Unknown\"]\n",
    "articles = articles.loc[articles.colour_group_name != \"Unknown\"]\n",
    "customers.dropna(axis=0, how='any', subset=[\"club_member_status\", \"age\"], inplace=True)\n",
    "# filter out transactions data with articles and customers ID\n",
    "transactions = transactions.loc[transactions['article_id'].isin(articles.article_id.unique())]\n",
    "transactions = transactions.loc[transactions['customer_id'].isin(customers.customer_id.unique())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 31983 rows of data from 880 users (users with suffication data)\n"
     ]
    }
   ],
   "source": [
    "# calculate customer interactions in transaction data\n",
    "# drop customers that only contain few interactions\n",
    "transactions[\"interaction\"] = 1\n",
    "transactions_temp = transactions.drop_duplicates(subset=[\"customer_id\", \"article_id\"])\n",
    "comb_transactions = transactions_temp[[\"customer_id\", \"interaction\"]].groupby(by=[\"customer_id\"], sort=False, as_index=False).sum([\"interaction\"])\n",
    "comb_transactions = comb_transactions.loc[comb_transactions.interaction >= 5]\n",
    "\n",
    "# randomly select part of the transaction data\n",
    "rand_userIds = np.random.choice(comb_transactions.customer_id.unique(), \n",
    "                                size=int(len(comb_transactions['customer_id'].unique())*0.001), \n",
    "                                replace=False)\n",
    "\n",
    "transactions = transactions.loc[transactions['customer_id'].isin(rand_userIds)]\n",
    "\n",
    "print('There are {} rows of data from {} users (users with suffication data)'.format(len(transactions), len(rand_userIds)))\n",
    "\n",
    "transactions.drop_duplicates(subset=[\"customer_id\", \"article_id\"], keep=\"first\", inplace=True)\n",
    "\n",
    "# merge transaction data with article and customer data\n",
    "transactions = transactions.merge(customers, how='left', left_on=[\"customer_id\"], right_on=[\"customer_id\"])\n",
    "transactions = transactions.merge(articles, how='left', left_on=[\"article_id\"], right_on=[\"article_id\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_id</th>\n",
       "      <th>article_id</th>\n",
       "      <th>price</th>\n",
       "      <th>sales_channel_id</th>\n",
       "      <th>club_member_status</th>\n",
       "      <th>age</th>\n",
       "      <th>product_group_name</th>\n",
       "      <th>colour_group_name</th>\n",
       "      <th>index_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.288010</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.953100</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.712215</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.717387</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.966737</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.382604</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>-0.966737</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.382604</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>-0.966737</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.382604</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   customer_id  article_id     price  sales_channel_id  club_member_status  \\\n",
       "0            0           0 -0.288010                 0                   0   \n",
       "1            1           1 -0.712215                 0                   0   \n",
       "2            2           2 -0.966737                 1                   0   \n",
       "3            2           3 -0.966737                 1                   0   \n",
       "4            2           4 -0.966737                 1                   0   \n",
       "\n",
       "        age  product_group_name  colour_group_name  index_name  \n",
       "0 -0.953100                   0                  0           0  \n",
       "1 -0.717387                   0                  0           0  \n",
       "2  0.382604                   1                  1           1  \n",
       "3  0.382604                   1                  2           1  \n",
       "4  0.382604                   1                  0           1  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# binarize categorical features club_member_status and sales_channel_id in transaction data\n",
    "lb = LabelBinarizer()\n",
    "transactions.sales_channel_id = lb.fit_transform(transactions.sales_channel_id)\n",
    "transactions.club_member_status = lb.fit_transform(transactions.club_member_status)\n",
    "\n",
    "# standardize numerical features age and price in transaction data\n",
    "std = StandardScaler()\n",
    "transactions[[\"price\", \"age\"]] = std.fit_transform(transactions[[\"price\", \"age\"]])\n",
    "\n",
    "# training set and test set\n",
    "transactions['rank_latest'] = transactions.groupby(['customer_id'])['t_dat'].rank(method='first', ascending=False)\n",
    "\n",
    "train_transactions = transactions[transactions['rank_latest'] != 1]\n",
    "test_transactions = transactions[transactions['rank_latest'] == 1]\n",
    "\n",
    "# drop articles that do not exist in training set\n",
    "test_product_list = list(set(test_transactions.article_id.unique()) & set(train_transactions.article_id.unique()))\n",
    "test_transactions = test_transactions.loc[test_transactions['article_id'].isin(test_product_list)]\n",
    "\n",
    "# drop columns that we no longer need\n",
    "drop_cols = [\"t_dat\", \"interaction\", \"rank_latest\"]\n",
    "train_transactions.drop(labels=drop_cols, axis=1, inplace=True)\n",
    "test_transactions.drop(labels=drop_cols, axis=1, inplace=True)\n",
    "\n",
    "\"\"\"reindex\"\"\"\n",
    "# map string type customer_id to int type\n",
    "customer_mapper = {}\n",
    "customer_keys = train_transactions.customer_id.unique()\n",
    "customer_values = list(range(len(train_transactions.customer_id.unique())))\n",
    "customer_mapper.update(zip(customer_keys, customer_values))\n",
    "\n",
    "# map string type article_id to int type\n",
    "product_mapper = {}\n",
    "product_keys = train_transactions.article_id.unique()\n",
    "product_values = list(range(len(train_transactions.article_id.unique())))\n",
    "product_mapper.update(zip(product_keys, product_values))\n",
    "\n",
    "# map color_group_name to int type\n",
    "color_mapper = {}\n",
    "color_keys = train_transactions.colour_group_name.unique()\n",
    "color_values = list(range(len(train_transactions.colour_group_name.unique())))\n",
    "color_mapper.update(zip(color_keys, color_values))\n",
    "\n",
    "# map color_group_name to int type\n",
    "product_group_mapper = {}\n",
    "product_group_keys = train_transactions.product_group_name.unique()\n",
    "product_group_values = list(range(len(train_transactions.product_group_name.unique())))\n",
    "product_group_mapper.update(zip(product_group_keys, product_group_values))\n",
    "\n",
    "# map index_name to int type\n",
    "index_name_mapper = {}\n",
    "index_name_keys = train_transactions.index_name.unique()\n",
    "index_name_values = list(range(len(train_transactions.index_name.unique())))\n",
    "index_name_mapper.update(zip(index_name_keys, index_name_values))\n",
    "\n",
    "# reindex categorical features based on feature mappers\n",
    "train_transactions[\"customer_id\"] = train_transactions[\"customer_id\"].map(customer_mapper)\n",
    "train_transactions[\"article_id\"] = train_transactions[\"article_id\"].map(product_mapper)\n",
    "train_transactions[\"colour_group_name\"] = train_transactions[\"colour_group_name\"].map(color_mapper)\n",
    "train_transactions[\"product_group_name\"] = train_transactions[\"product_group_name\"].map(product_group_mapper)\n",
    "train_transactions[\"index_name\"] = train_transactions[\"index_name\"].map(index_name_mapper)\n",
    "test_transactions[\"customer_id\"] = test_transactions[\"customer_id\"].map(customer_mapper)\n",
    "test_transactions[\"article_id\"] = test_transactions[\"article_id\"].map(product_mapper)\n",
    "test_transactions[\"colour_group_name\"] = test_transactions[\"colour_group_name\"].map(color_mapper)\n",
    "test_transactions[\"product_group_name\"] = test_transactions[\"product_group_name\"].map(product_group_mapper)\n",
    "test_transactions[\"index_name\"] = test_transactions[\"index_name\"].map(index_name_mapper)\n",
    "\n",
    "# get a list of all articles id\n",
    "all_products_id = train_transactions[\"article_id\"].unique()\n",
    "\n",
    "train_transactions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16450"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_transactions.article_id.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "def sparse_to_tensor(sparse_matrix):\n",
    "    \"\"\"\n",
    "    Transform scipy coo matrix to pytorch sparse tensor\n",
    "    \"\"\"\n",
    "    sparse_matrix = sparse_matrix.tocoo()\n",
    "    values = sparse_matrix.data\n",
    "    indices = (sparse_matrix.row, sparse_matrix.col) # np.vstack\n",
    "    shape = sparse_matrix.shape\n",
    "\n",
    "    i = torch.LongTensor(indices)\n",
    "    v = torch.DoubleTensor(values)\n",
    "    s = torch.Size(shape)\n",
    "\n",
    "    return torch.sparse.DoubleTensor(i, v, s)\n",
    "\n",
    "def sparse_batch_collate(batch): \n",
    "    \"\"\"\n",
    "    Collate function which to transform scipy csr matrix to pytorch sparse tensor\n",
    "    \"\"\"\n",
    "    # batch[0] since it is returned as a one element list\n",
    "\n",
    "    customer_batch, product_batch, targets_batch = batch[0]\n",
    "    \n",
    "    if type(customer_batch[0]) == csr_matrix:\n",
    "        customer_batch = customer_batch.tocoo() # removed vstack\n",
    "        customer_batch = sparse_to_tensor(customer_batch)\n",
    "    else:\n",
    "        customer_batch = torch.DoubleTensor(customer_batch)\n",
    "\n",
    "    if type(product_batch[0]) == csr_matrix:\n",
    "        product_batch = product_batch.tocoo() # removed vstack\n",
    "        product_batch = sparse_to_tensor(product_batch)\n",
    "    else:\n",
    "        product_batch = torch.DoubleTensor(product_batch)\n",
    "    \n",
    "    if type(targets_batch[0]) == csr_matrix:\n",
    "        targets_batch = targets_batch.tocoo() # removed vstack\n",
    "        targets_batch = sparse_to_tensor(targets_batch)\n",
    "    else:\n",
    "        targets_batch = torch.DoubleTensor(targets_batch)\n",
    "    \n",
    "    return customer_batch, product_batch, targets_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HMSaleTrainDataLoader(Dataset):\n",
    "    \"\"\"HMSaleTrainDataLoader Training set of HM sales data\n",
    "\n",
    "    Args:\n",
    "        transactions (pd.DataFrame): Dataframe of transaction records\n",
    "        all_products_id (list): A list contains all product ids\n",
    "    \"\"\"\n",
    "    def __init__(self, transactions, all_products_id):\n",
    "        self.customers, self.products, self.prices, self.sales_channels, \\\n",
    "        self.club_status, self.age_groups, self.product_groups, self.color_groups, \\\n",
    "        self.index_name, self.labels = self.get_dataset(transactions, all_products_id)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.customers)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.customers[idx], self.products[idx], self.prices[idx], self.sales_channels[idx], self.club_status[idx], \\\n",
    "               self.age_groups[idx], self.product_groups[idx], self.color_groups[idx], self.index_name[idx], self.labels[idx]\n",
    "    \n",
    "    def get_dataset(self, transactions, all_products_id):\n",
    "        customers, products, prices, sales_channels, club_status, age_groups, product_groups, color_groups, index_name, labels  = [], [], [], [], [], [], [], [], [], []\n",
    "        customer_product_set = set(zip(transactions[\"customer_id\"], transactions[\"article_id\"], \n",
    "                                       transactions[\"price\"], transactions[\"sales_channel_id\"], \n",
    "                                       transactions[\"club_member_status\"], transactions[\"age\"], \n",
    "                                       transactions[\"product_group_name\"], transactions[\"colour_group_name\"], transactions[\"index_name\"]))\n",
    "        \n",
    "        \"\"\"negative sampling\"\"\"\n",
    "        # set up negative:positive ratio as 4:1\n",
    "        negative_samples = 4\n",
    "\n",
    "        for u, i, price, sale, club, age, product, color, index in tqdm(customer_product_set):\n",
    "            customers.append(u)\n",
    "            products.append(i)\n",
    "            prices.append(price)\n",
    "            sales_channels.append(sale)\n",
    "            club_status.append(club)\n",
    "            age_groups.append(age)\n",
    "            product_groups.append(product)\n",
    "            color_groups.append(color)\n",
    "            index_name.append(index)\n",
    "            labels.append(1)\n",
    "            for _ in range(negative_samples):\n",
    "                negative_product = np.random.choice(all_products_id)\n",
    "                while (u, negative_product, price, sale, club, age, product, color, index) in customer_product_set:\n",
    "                    negative_product = np.random.choice(all_products_id)\n",
    "                customers.append(u)\n",
    "                products.append(negative_product)\n",
    "                prices.append(price)\n",
    "                sales_channels.append(sale)\n",
    "                club_status.append(club)\n",
    "                age_groups.append(age)\n",
    "                product_groups.append(product)\n",
    "                color_groups.append(color)\n",
    "                index_name.append(index)\n",
    "                labels.append(0)\n",
    "        return customers, products, prices, sales_channels, club_status, age_groups, product_groups, color_groups, index_name, torch.tensor(labels)\n",
    "    \n",
    "def binary_acc(y_pred, y_test):\n",
    "    y_pred_label = torch.softmax(y_pred, dim=1)\n",
    "    _, y_pred_label = torch.max(y_pred_label, dim = 1)\n",
    "    correct_pred = (y_pred_label == y_test).sum()\n",
    "    acc = correct_pred/y_test.shape[0]\n",
    "    return acc  \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NCF(nn.Module):\n",
    "    \"\"\"NCF - Neural Collaborative Filtering proposed by He et al.\n",
    "\n",
    "    Args:\n",
    "        num_users (int): Number of users\n",
    "        num_items (iut): Number of products\n",
    "        num_product_groups (int): Number of product groups\n",
    "        num_color_groups: (int): Number of color groups\n",
    "        num_index_name: (int): Number of index name\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "            self, \n",
    "            num_users: int, \n",
    "            num_items: int,\n",
    "            num_product_groups: int,\n",
    "            num_color_groups: int,\n",
    "            num_index_name: int,\n",
    "            user_embedding_dim: int = 16,\n",
    "            item_embedding_dim: int = 32,\n",
    "            product_group_embedding_dim: int = 10,\n",
    "            color_group_embedding_dim: int = 8,\n",
    "            index_name_embedding_dim: int = 6,\n",
    "            input_size: int = 76,\n",
    "            hidden_size_1: int = 64,\n",
    "            hidden_size_2: int = 128,\n",
    "            output_size: int = 32,\n",
    "            num_hidden_layers: int = 2,\n",
    "            num_classes: int = 2,\n",
    "        ):\n",
    "            super().__init__()\n",
    "            # embedding layers for categorical features and user-item interaction\n",
    "            self.user_embedding_layer = nn.Embedding(num_embeddings=num_users, embedding_dim=user_embedding_dim)\n",
    "            self.item_embedding_layer = nn.Embedding(num_embeddings=num_items, embedding_dim=item_embedding_dim)\n",
    "            self.product_group_embedding_layer = nn.Embedding(num_embeddings=num_product_groups, embedding_dim=product_group_embedding_dim)\n",
    "            self.color_group_embedding_layer = nn.Embedding(num_embeddings=num_color_groups, embedding_dim=color_group_embedding_dim)\n",
    "            self.index_name_embedding_layer = nn.Embedding(num_embeddings=num_index_name, embedding_dim=index_name_embedding_dim)\n",
    "\n",
    "            self.relu = nn.LeakyReLU()\n",
    "            self.fcs = nn.Sequential()\n",
    "            if user_embedding_dim and item_embedding_dim is not None:\n",
    "                in_channels = (\n",
    "                    [input_size] \n",
    "                    + [hidden_size_2 + hidden_size_2]*num_hidden_layers \n",
    "                    + [hidden_size_2]\n",
    "                    + [hidden_size_1]\n",
    "                    + [output_size]\n",
    "                )\n",
    "            else:\n",
    "                raise ValueError\n",
    "            for i in range(len(in_channels)):\n",
    "                if i != len(in_channels)-1:\n",
    "                    self.fcs.append(nn.Linear(in_features=in_channels[i],  out_features=in_channels[i+1]))\n",
    "                else:\n",
    "                    self.fcs.append(nn.Linear(in_features=in_channels[i],  out_features=num_classes))\n",
    "    \n",
    "    def forward(self, user_input, item_input, prices, sales_channels, club_status, age_groups, product_groups, color_groups, index_name):\n",
    "\n",
    "        user_embedding = self.user_embedding_layer(user_input)\n",
    "        item_embedding = self.item_embedding_layer(item_input)\n",
    "        product_group_embedding = self.product_group_embedding_layer(product_groups)\n",
    "        color_group_embedding = self.color_group_embedding_layer(color_groups)\n",
    "        index_name_embedding = self.index_name_embedding_layer(index_name)\n",
    "        concat_embedding = torch.cat([user_embedding, item_embedding, product_group_embedding, color_group_embedding, index_name_embedding], dim=-1)\n",
    "\n",
    "        concat_input = torch.cat([prices.reshape(-1, 1), sales_channels.reshape(-1, 1), club_status.reshape(-1, 1), age_groups.reshape(-1, 1)], dim=-1)\n",
    "        concat_embedding = torch.cat([concat_embedding, concat_input], dim=-1)\n",
    "\n",
    "        for fc_layer in self.fcs:\n",
    "            concat_embedding = fc_layer(concat_embedding)\n",
    "            concat_embedding = self.relu(concat_embedding)\n",
    "        #pred = F.softmax(concat_embedding)\n",
    "        return concat_embedding\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_users: 880\n",
      "num_items: 16450\n",
      "num_product_groups: 13\n",
      "num_color_groups: 49\n",
      "num_index_name: 10\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a7bbfe35eadd428e900e8e278143e6f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/26416 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NCF(\n",
      "  (user_embedding_layer): Embedding(880, 16)\n",
      "  (item_embedding_layer): Embedding(16450, 32)\n",
      "  (product_group_embedding_layer): Embedding(13, 10)\n",
      "  (color_group_embedding_layer): Embedding(49, 8)\n",
      "  (index_name_embedding_layer): Embedding(10, 6)\n",
      "  (relu): LeakyReLU(negative_slope=0.01)\n",
      "  (fcs): Sequential(\n",
      "    (0): Linear(in_features=76, out_features=256, bias=True)\n",
      "    (1): Linear(in_features=256, out_features=256, bias=True)\n",
      "    (2): Linear(in_features=256, out_features=128, bias=True)\n",
      "    (3): Linear(in_features=128, out_features=64, bias=True)\n",
      "    (4): Linear(in_features=64, out_features=32, bias=True)\n",
      "    (5): Linear(in_features=32, out_features=2, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a0bef9dd4bf746258586824964b3364c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 000: | Loss: 0.508299 | Acc: 0.7953\n",
      "Epoch 001: | Loss: 0.498014 | Acc: 0.8000\n",
      "Epoch 002: | Loss: 0.480907 | Acc: 0.8013\n",
      "Epoch 003: | Loss: 0.426637 | Acc: 0.8254\n",
      "Epoch 004: | Loss: 0.359455 | Acc: 0.8584\n",
      "Epoch 005: | Loss: 0.298139 | Acc: 0.8878\n",
      "Epoch 006: | Loss: 0.242199 | Acc: 0.9108\n",
      "Epoch 007: | Loss: 0.194121 | Acc: 0.9302\n",
      "Epoch 008: | Loss: 0.153272 | Acc: 0.9453\n",
      "Epoch 009: | Loss: 0.115939 | Acc: 0.9592\n",
      "Epoch 010: | Loss: 0.086293 | Acc: 0.9695\n",
      "Epoch 011: | Loss: 0.061958 | Acc: 0.9784\n",
      "Epoch 012: | Loss: 0.043000 | Acc: 0.9853\n",
      "Epoch 013: | Loss: 0.031936 | Acc: 0.9891\n",
      "Epoch 014: | Loss: 0.023120 | Acc: 0.9918\n",
      "Epoch 015: | Loss: 0.017263 | Acc: 0.9941\n",
      "Epoch 016: | Loss: 0.014530 | Acc: 0.9951\n",
      "Epoch 017: | Loss: 0.012531 | Acc: 0.9958\n",
      "Epoch 018: | Loss: 0.011429 | Acc: 0.9961\n",
      "Epoch 019: | Loss: 0.009173 | Acc: 0.9971\n",
      "Epoch 020: | Loss: 0.007350 | Acc: 0.9978\n",
      "Epoch 021: | Loss: 0.007916 | Acc: 0.9976\n",
      "Epoch 022: | Loss: 0.006429 | Acc: 0.9978\n",
      "Epoch 023: | Loss: 0.006654 | Acc: 0.9978\n",
      "Epoch 024: | Loss: 0.005621 | Acc: 0.9984\n",
      "Epoch 025: | Loss: 0.006254 | Acc: 0.9980\n",
      "Epoch 026: | Loss: 0.005340 | Acc: 0.9983\n",
      "Epoch 027: | Loss: 0.006323 | Acc: 0.9980\n",
      "Epoch 028: | Loss: 0.005126 | Acc: 0.9984\n",
      "Epoch 029: | Loss: 0.004824 | Acc: 0.9986\n",
      "Epoch 030: | Loss: 0.004305 | Acc: 0.9986\n",
      "Epoch 031: | Loss: 0.005582 | Acc: 0.9982\n",
      "Epoch 032: | Loss: 0.005274 | Acc: 0.9984\n",
      "Epoch 033: | Loss: 0.006399 | Acc: 0.9981\n",
      "Epoch 034: | Loss: 0.004651 | Acc: 0.9986\n",
      "Epoch 035: | Loss: 0.004257 | Acc: 0.9987\n",
      "Epoch 036: | Loss: 0.003777 | Acc: 0.9988\n",
      "Epoch 037: | Loss: 0.004337 | Acc: 0.9987\n",
      "Epoch 038: | Loss: 0.003845 | Acc: 0.9988\n",
      "Epoch 039: | Loss: 0.003692 | Acc: 0.9988\n",
      "Epoch 040: | Loss: 0.003244 | Acc: 0.9990\n",
      "Epoch 041: | Loss: 0.002501 | Acc: 0.9993\n",
      "Epoch 042: | Loss: 0.002970 | Acc: 0.9991\n",
      "Epoch 043: | Loss: 0.004223 | Acc: 0.9987\n",
      "Epoch 044: | Loss: 0.005419 | Acc: 0.9984\n",
      "Epoch 045: | Loss: 0.004034 | Acc: 0.9987\n",
      "Epoch 046: | Loss: 0.003144 | Acc: 0.9991\n",
      "Epoch 047: | Loss: 0.004471 | Acc: 0.9987\n",
      "Epoch 048: | Loss: 0.002878 | Acc: 0.9993\n",
      "Epoch 049: | Loss: 0.002457 | Acc: 0.9993\n",
      "\n",
      "Best Accuracy: 0.999\n"
     ]
    }
   ],
   "source": [
    "# set up hyper-parameters\n",
    "learning_rate = 0.005\n",
    "epoch = 40\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "torch.autograd.set_detect_anomaly(True)\n",
    "\n",
    "# set up dataset for training\n",
    "num_users = len(train_transactions.customer_id.unique())\n",
    "print(\"num_users:\", num_users)\n",
    "num_items = len(all_products_id)\n",
    "print(\"num_items:\", num_items)\n",
    "num_product_groups = len(train_transactions.product_group_name.unique())\n",
    "print(\"num_product_groups:\", num_product_groups)\n",
    "num_color_groups = len(train_transactions.colour_group_name.unique())\n",
    "print(\"num_color_groups:\", num_color_groups)\n",
    "num_index_name = len(train_transactions.index_name.unique())\n",
    "print(\"num_index_name:\", num_index_name)\n",
    "train_data = HMSaleTrainDataLoader(train_transactions, all_products_id)\n",
    "train_loader = DataLoader(train_data, batch_size=1024, shuffle=True)\n",
    "\n",
    "# initiate model for training\n",
    "model = NCF(num_users=num_users, num_items=num_items, num_product_groups=num_product_groups, num_color_groups=num_color_groups, num_index_name=num_index_name)\n",
    "model.to(device)\n",
    "print(model)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "model.train()\n",
    "best_acc = 0.0\n",
    "for e in tqdm(range(epoch)):\n",
    "    epoch_loss = 0.0\n",
    "    epoch_acc = 0.0\n",
    "    for customer_batch, product_batch, prices_batch, sales_channels_batch, club_status_batch, age_groups_batch, product_groups_batch, color_groups_batch, index_name_batch, label_batch in train_loader:\n",
    "        customer_batch, product_batch, prices_batch, sales_channels_batch, club_status_batch, \\\n",
    "        age_groups_batch, product_groups_batch, color_groups_batch, index_name_batch, label_batch \\\n",
    "        = customer_batch.to(device), product_batch.to(device), prices_batch.to(device), \\\n",
    "        sales_channels_batch.to(device), club_status_batch.to(device), age_groups_batch.to(device), \\\n",
    "        product_groups_batch.to(device), color_groups_batch.to(device), index_name_batch.to(device), label_batch.to(device), \n",
    "        optimizer.zero_grad()\n",
    "        y_pred = model(customer_batch, product_batch, prices_batch.float(), sales_channels_batch.float(), club_status_batch.float(), age_groups_batch.float(), product_groups_batch, color_groups_batch, index_name_batch)\n",
    "        loss = loss_fn(y_pred, label_batch)\n",
    "        acc = binary_acc(y_pred, label_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc += acc.item()\n",
    "        cur_acc = epoch_acc/len(train_loader)\n",
    "    if cur_acc > best_acc:\n",
    "        best_acc = cur_acc\n",
    "        torch.save(model.state_dict(), 'best_model.pt')\n",
    "    print(f'Epoch {e+0:03}: | Loss: {epoch_loss/len(train_loader):.6f} | Acc: {epoch_acc/len(train_loader):.4f}')\n",
    "\n",
    "print(f'\\nBest Accuracy: {best_acc:.3f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_acc(y_pred, y_test):\n",
    "    y_pred_label = torch.softmax(y_pred, dim=1)\n",
    "    _, y_pred_label = torch.max(y_pred_label, dim = 1)\n",
    "    correct_pred = (y_pred_label == y_test).sum()\n",
    "    acc = correct_pred/y_test.shape[0]\n",
    "    print(\"pred_test\")\n",
    "    print(correct_pred)\n",
    "    print(y_pred_label)\n",
    "    return acc  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be7de1d706c14f4eb72c30176339af79",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/498 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Accuracy on test set: 0.877\n"
     ]
    }
   ],
   "source": [
    "model = NCF(num_users=num_users, num_items=num_items, num_product_groups=num_product_groups, num_color_groups=num_color_groups, num_index_name=num_index_name)\n",
    "test_data = HMSaleTrainDataLoader(test_transactions, all_products_id)\n",
    "test_dataloader = DataLoader(test_data, batch_size=64, shuffle=True)\n",
    "\n",
    "model.load_state_dict(torch.load('best_model.pt'))\n",
    "model.to(device)\n",
    "\n",
    "model.eval()\n",
    "test_acc = 0.0\n",
    "with torch.no_grad():\n",
    "    for customer_batch, product_batch, prices_batch, sales_channels_batch, club_status_batch, age_groups_batch, product_groups_batch, color_groups_batch, index_name_batch, label_batch in test_dataloader:\n",
    "        customer_batch, product_batch, prices_batch, sales_channels_batch, club_status_batch, \\\n",
    "        age_groups_batch, product_groups_batch, color_groups_batch, index_name_batch, label_batch \\\n",
    "        = customer_batch.to(device), product_batch.to(device), prices_batch.to(device), \\\n",
    "        sales_channels_batch.to(device), club_status_batch.to(device), age_groups_batch.to(device), \\\n",
    "        product_groups_batch.to(device), color_groups_batch.to(device), index_name_batch.to(device), label_batch.to(device), \n",
    "        \n",
    "        y_pred = model(customer_batch, product_batch, prices_batch.float(), sales_channels_batch.float(), club_status_batch.float(), age_groups_batch.float(), product_groups_batch, color_groups_batch, index_name_batch)\n",
    "        acc = binary_acc(y_pred, label_batch)\n",
    "        test_acc += acc.item()\n",
    "    test_acc = test_acc/len(test_dataloader)\n",
    "\n",
    "print(f'\\nClassification Accuracy on test set: {test_acc:.3f}')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hit(ng_item, pred_items):\n",
    "\tif ng_item in pred_items:\n",
    "\t\treturn 1\n",
    "\treturn 0\n",
    "\n",
    "\n",
    "def ndcg(ng_item, pred_items):\n",
    "\tif ng_item in pred_items:\n",
    "\t\tindex = pred_items.index(ng_item)\n",
    "\t\treturn np.reciprocal(np.log2(index+2))\n",
    "\treturn 0\n",
    "\n",
    "\n",
    "def metrics(model, test_loader, top_k, device):\n",
    "\tHR, NDCG = [], []\n",
    "\n",
    "\tfor user, item, label in test_loader:\n",
    "\t\tuser = user.to(device)\n",
    "\t\titem = item.to(device)\n",
    "\n",
    "\t\tpredictions = model(user, item)\n",
    "\t\t_, indices = torch.topk(predictions, top_k)\n",
    "\t\trecommends = torch.take(\n",
    "\t\t\t\titem, indices).cpu().numpy().tolist()\n",
    "\n",
    "\t\tng_item = item[0].item() # leave one-out evaluation has only one item per user\n",
    "\t\tHR.append(hit(ng_item, recommends))\n",
    "\t\tNDCG.append(ndcg(ng_item, recommends))\n",
    "\n",
    "\treturn np.mean(HR), np.mean(NDCG)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7857ada9c2c05e5ee75d334d60fb77cca110ad03375c3b02029444557fa6212d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
