{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "dataDir = Path.cwd().parent.parent/'backup/HM_data'\n",
    "np.random.seed(666)\n",
    "\n",
    "transactions = pd.read_csv(dataDir/'transactions.csv')\n",
    "# articles = pd.read_csv(dataDir/'articles.csv')\n",
    "# customers = pd.read_csv(dataDir/'customers.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(transactions.customer_id.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_userIds = np.random.choice(transactions['customer_id'].unique(), \n",
    "                                size=int(len(transactions['customer_id'].unique())*0.1), \n",
    "                                replace=False)\n",
    "\n",
    "transactions = transactions.loc[transactions['customer_id'].isin(rand_userIds)]\n",
    "transactions[\"interaction\"] = 1\n",
    "\n",
    "print('There are {} rows of data from {} users'.format(len(transactions), len(rand_userIds)))\n",
    "\n",
    "# map string type customer_id to int type\n",
    "customer_mapper = {}\n",
    "keys = transactions.customer_id.unique()\n",
    "values = list(range(1, len(transactions.customer_id.unique())+1))\n",
    "customer_mapper.update(zip(keys, values))\n",
    "\n",
    "transactions[\"customer_id\"] = transactions[\"customer_id\"].map(customer_mapper)\n",
    "transactions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training set and test set\n",
    "\n",
    "transactions['rank_latest'] = transactions.groupby(['customer_id'])['t_dat'].rank(method='first', ascending=False)\n",
    "\n",
    "train_transactions = transactions[transactions['rank_latest'] != 1]\n",
    "test_transactions = transactions[transactions['rank_latest'] == 1]\n",
    "# get a list of all articles id\n",
    "all_products_id = transactions[\"article_id\"].unique()\n",
    "\n",
    "# drop columns that we no longer need\n",
    "# train_transactions = train_transactions[['customer_id', 'article_id', 'price']]\n",
    "# test_transactions = test_transactions[['customer_id', 'article_id', 'price']]\n",
    "# comb_transactions = train_transactions.groupby(by=[\"customer_id\", \"article_id\"], sort=False, as_index=False).sum([\"interaction\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HMSaleTrainDataLoader(Dataset):\n",
    "    \"\"\"HMSaleTrainDataLoader Training set of HM sales data\n",
    "\n",
    "    Args:\n",
    "        transaction (pd.DataFrame): Dataframe of transaction records\n",
    "        products (list): A list contains all product ids\n",
    "    \"\"\"\n",
    "    def __init__(self, transactions, all_products_id):\n",
    "        self.customers, self.products, self.labels = self.get_dataset(transactions, all_products_id)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.customers)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.customers[idx], self.products[idx], self.labels[idx]\n",
    "    \n",
    "    def get_dataset(self, transactions, all_products_id):\n",
    "        customers, products, labels = [], [], []\n",
    "        customer_product_set = set(zip(train_transactions['customer_id'], train_transactions['article_id']))\n",
    "\n",
    "        # set up negative:positive ratio as 4:1\n",
    "        negative_samples = 4\n",
    "\n",
    "        for u, i in tqdm(customer_product_set):\n",
    "            customers.append(u)\n",
    "            products.append(i)\n",
    "            labels.append(1)\n",
    "            for _ in range(negative_samples):\n",
    "                negative_product = np.random.choice(all_products_id)\n",
    "                while (u, negative_product) in customer_product_set:\n",
    "                    negative_product = np.random.choice(all_products_id)\n",
    "                customers.append(u)\n",
    "                products.append(negative_product)\n",
    "                labels.append(0)    \n",
    "        return torch.tensor(customers), torch.tensor(products), torch.tensor(labels)   \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HEHE = HMSaleTrainDataLoader(transactions, all_products_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HEHE.__getitem__(1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7857ada9c2c05e5ee75d334d60fb77cca110ad03375c3b02029444557fa6212d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
