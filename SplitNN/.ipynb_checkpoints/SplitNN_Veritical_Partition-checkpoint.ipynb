{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0bf6beab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import syft as sy\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "np.random.seed(666)\n",
    "\n",
    "hook = sy.TorchHook(torch)\n",
    "from Distributed_HM_Data import Distributed_HM, binary_acc\n",
    "\n",
    "dataDir = Path.cwd().parent/'Data/'\n",
    "print(\"Test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "338652ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HMSaleTrainDataLoader(Dataset):\n",
    "    \"\"\"HMSaleTrainDataLoader Training set of HM sales data\n",
    "\n",
    "    Args:\n",
    "        transactions (pd.DataFrame): Dataframe of transaction records\n",
    "        all_products_id (list): A list contains all product ids\n",
    "    \"\"\"\n",
    "    def __init__(self, transactions, all_products_id):\n",
    "        self.customers, self.products, self.prices, self.sales_channels, \\\n",
    "        self.club_status, self.age_groups, self.product_groups, self.color_groups, \\\n",
    "        self.index_name, self.labels = self.get_dataset(transactions, all_products_id)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.customers)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.customers[idx], self.products[idx], self.prices[idx], self.sales_channels[idx], self.club_status[idx], \\\n",
    "               self.age_groups[idx], self.product_groups[idx], self.color_groups[idx], self.index_name[idx], self.labels[idx]\n",
    "    \n",
    "    def get_dataset(self, transactions, all_products_id):\n",
    "        customers, products, prices, sales_channels, club_status, age_groups, product_groups, color_groups, index_name, labels  = [], [], [], [], [], [], [], [], [], []\n",
    "        customer_product_set = set(zip(transactions[\"customer_id\"], transactions[\"article_id\"], \n",
    "                                       transactions[\"price\"], transactions[\"sales_channel_id\"], \n",
    "                                       transactions[\"club_member_status\"], transactions[\"age\"], \n",
    "                                       transactions[\"product_group_name\"], transactions[\"colour_group_name\"], transactions[\"index_name\"]))\n",
    "        \n",
    "        \"\"\"negative sampling\"\"\"\n",
    "        # set up negative:positive ratio as 4:1\n",
    "        negative_samples = 4\n",
    "\n",
    "        for u, i, price, sale, club, age, product, color, index in tqdm(customer_product_set):\n",
    "            customers.append(u)\n",
    "            products.append(i)\n",
    "            prices.append(price)\n",
    "            sales_channels.append(sale)\n",
    "            club_status.append(club)\n",
    "            age_groups.append(age)\n",
    "            product_groups.append(product)\n",
    "            color_groups.append(color)\n",
    "            index_name.append(index)\n",
    "            labels.append(1)\n",
    "            for _ in range(negative_samples):\n",
    "                negative_product = np.random.choice(all_products_id)\n",
    "                while (u, negative_product, price, sale, club, age, product, color, index) in customer_product_set:\n",
    "                    negative_product = np.random.choice(all_products_id)\n",
    "                customers.append(u)\n",
    "                products.append(negative_product)\n",
    "                prices.append(price)\n",
    "                sales_channels.append(sale)\n",
    "                club_status.append(club)\n",
    "                age_groups.append(age)\n",
    "                product_groups.append(product)\n",
    "                color_groups.append(color)\n",
    "                index_name.append(index)\n",
    "                labels.append(0)\n",
    "        return torch.tensor(customers), torch.tensor(products), torch.tensor(prices), torch.tensor(sales_channels), \\\n",
    "               torch.tensor(club_status), torch.tensor(age_groups), torch.tensor(product_groups), torch.tensor(color_groups), \\\n",
    "               torch.tensor(index_name), torch.tensor(labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1bfed2f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0cda34fa93bd440eb13970431d17ca51",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1403 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "hm_data = pd.read_csv(dataDir/'small_train.csv')\n",
    "all_products_id = hm_data[\"article_id\"].unique()\n",
    "train_data = HMSaleTrainDataLoader(hm_data, all_products_id)\n",
    "train_loader = DataLoader(train_data, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2534ade6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up virtual worker\n",
    "sales_domain = sy.VirtualWorker(hook, id=\"sales_domain\")\n",
    "customer_domain = sy.VirtualWorker(hook, id=\"customer_domain\")\n",
    "product_domain = sy.VirtualWorker(hook, id=\"product_domain\")\n",
    "server = sy.VirtualWorker(hook, id=\"server\")\n",
    "\n",
    "data_owners = (sales_domain, customer_domain, product_domain)\n",
    "model_locations = [sales_domain, customer_domain, product_domain, server]\n",
    "\n",
    "distributed_trainloader = Distributed_HM(data_owners=data_owners, data_loader=train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "2561077a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SalesNN(nn.Module):\n",
    "    \"\"\" Partial model for sales domain\n",
    "    Args:\n",
    "        num_users (int): Number of users\n",
    "        num_items (int): Number of products\n",
    "        prices (float): price of transactions\n",
    "        sales_channels (float): sales channels\n",
    "    \n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "            self, \n",
    "            num_users: int, \n",
    "            num_items: int,\n",
    "            input_size: int = 194,\n",
    "            user_embedding_dim: int = 64,\n",
    "            item_embedding_dim: int = 128,\n",
    "            hidden_size_1: int = 64,\n",
    "            hidden_size_2: int = 256,\n",
    "            output_size: int = 32,\n",
    "        ):\n",
    "        super().__init__()\n",
    "        self.user_embedding_layer = nn.Embedding(num_embeddings=num_users, embedding_dim=user_embedding_dim)\n",
    "        self.item_embedding_layer = nn.Embedding(num_embeddings=num_items, embedding_dim=item_embedding_dim)\n",
    "        self.relu = nn.LeakyReLU()\n",
    "        self.encoder = nn.Sequential()\n",
    "        if num_users and num_items is not None:\n",
    "                in_channels = (\n",
    "                    [input_size] \n",
    "                    + [hidden_size_2]\n",
    "                    + [hidden_size_1]\n",
    "                    + [output_size]\n",
    "                )\n",
    "        else:\n",
    "            raise ValueError\n",
    "        for i in range(len(in_channels)-1):\n",
    "            if i != len(in_channels)-1:\n",
    "                self.encoder.append(nn.Linear(in_features=in_channels[i], out_features=in_channels[i+1]))\n",
    "        \n",
    "    def forward(self, user_input, item_input, prices, sales_channels):\n",
    "        user_embedding = self.user_embedding_layer(user_input)\n",
    "        item_embedding = self.item_embedding_layer(item_input)\n",
    "        latent_vec = torch.cat([user_embedding, item_embedding, prices, sales_channels], dim=-1)\n",
    "        \n",
    "        for layer in self.encoder:\n",
    "            latent_vec = layer(latent_vec)\n",
    "            latent_vec = self.relu(latent_vec)\n",
    "        \n",
    "        return latent_vec\n",
    "\n",
    "class CustomersNN(nn.Module):\n",
    "    \"\"\" Partial model for customer domain\n",
    "    Args:\n",
    "        club_status (int): active or inactive customers' status\n",
    "        age_groups (int): age of customers\n",
    "    \n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "            self,\n",
    "            input_size: int = 2,\n",
    "            hidden_size_1: int = 16,\n",
    "            hidden_size_2: int = 32,\n",
    "            output_size: int = 8,\n",
    "        ):\n",
    "        super().__init__()\n",
    "        self.relu = nn.LeakyReLU()\n",
    "        self.encoder = nn.Sequential()\n",
    "        in_channels = (\n",
    "                    [input_size] \n",
    "                    + [hidden_size_2]\n",
    "                    + [hidden_size_1]\n",
    "                    + [output_size]\n",
    "                )\n",
    "        for i in range(len(in_channels)-1):\n",
    "            if i != len(in_channels)-1:\n",
    "                self.encoder.append(nn.Linear(in_features=in_channels[i], out_features=in_channels[i+1]))\n",
    "        \n",
    "    def forward(self, club_status, age_groups):\n",
    "        \n",
    "        latent_vec = torch.cat([club_status, age_groups], dim=-1)\n",
    "        \n",
    "        for layer in self.encoder:\n",
    "            latent_vec = layer(latent_vec)\n",
    "            latent_vec = self.relu(latent_vec)\n",
    "        \n",
    "        return latent_vec\n",
    "\n",
    "class ProductsNN(nn.Module):\n",
    "    \"\"\" Partial model for product domain\n",
    "    Args:\n",
    "        num_product_groups (int): Number of product groups\n",
    "        num_color_groups: (int): Number of color groups\n",
    "        num_index_name: (int): Number of index name\n",
    "    \n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "            self,\n",
    "            num_product_groups: int,\n",
    "            num_color_groups: int,\n",
    "            num_index_name: int,\n",
    "            product_group_embedding_dim: int = 8,\n",
    "            color_group_embedding_dim: int = 16,\n",
    "            index_name_embedding_dim: int = 6,\n",
    "            input_size: int = 30,\n",
    "            hidden_size_1: int = 32,\n",
    "            hidden_size_2: int = 64,\n",
    "            output_size: int = 16,\n",
    "        ):\n",
    "        super().__init__()\n",
    "        self.product_group_embedding_layer = nn.Embedding(num_embeddings=num_product_groups, embedding_dim=product_group_embedding_dim)\n",
    "        self.color_group_embedding_layer = nn.Embedding(num_embeddings=num_color_groups, embedding_dim=color_group_embedding_dim)\n",
    "        self.index_name_embedding_layer = nn.Embedding(num_embeddings=num_index_name, embedding_dim=index_name_embedding_dim)\n",
    "\n",
    "        self.relu = nn.LeakyReLU()\n",
    "        self.encoder = nn.Sequential()\n",
    "        if num_product_groups and num_color_groups and num_index_name is not None:\n",
    "                in_channels = (\n",
    "                    [input_size] \n",
    "                    + [hidden_size_2]\n",
    "                    + [hidden_size_1]\n",
    "                    + [output_size]\n",
    "                )\n",
    "        else:\n",
    "            raise ValueError\n",
    "        for i in range(len(in_channels)-1):\n",
    "            if i != len(in_channels)-1:\n",
    "                self.encoder.append(nn.Linear(in_features=in_channels[i], out_features=in_channels[i+1]))\n",
    "        \n",
    "    def forward(self, product_groups, color_groups, index_name):\n",
    "        product_group_embedding = self.product_group_embedding_layer(product_groups)\n",
    "        color_group_embedding = self.color_group_embedding_layer(color_groups)\n",
    "        index_name_embedding = self.index_name_embedding_layer(index_name)\n",
    "        latent_vec = torch.cat([product_group_embedding, color_group_embedding, index_name_embedding], dim=-1)\n",
    "        \n",
    "        for layer in self.encoder:\n",
    "            latent_vec = layer(latent_vec)\n",
    "            latent_vec = self.relu(latent_vec)\n",
    "        \n",
    "        return latent_vec\n",
    "\n",
    "class GovernanceNN(nn.Module):\n",
    "    \"\"\" Partial model for goverance side\n",
    "    Args:\n",
    "        agg_latent_input (int): aggregated input of latent vectors from client models\n",
    "    \n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "            self,\n",
    "            input_size: int = 56,\n",
    "            hidden_size_1: int = 128,\n",
    "            hidden_size_2: int = 64,\n",
    "            output_size: int = 2,\n",
    "        ):\n",
    "        super().__init__()\n",
    "        self.relu = nn.LeakyReLU()\n",
    "        self.decoder = nn.Sequential()\n",
    "        in_channels = (\n",
    "                    [input_size] \n",
    "                    + [hidden_size_2]\n",
    "                    + [hidden_size_1]\n",
    "                    + [output_size]\n",
    "                )\n",
    "        for i in range(len(in_channels)-1):\n",
    "            if i != len(in_channels)-1:\n",
    "                self.decoder.append(nn.Linear(in_features=in_channels[i], out_features=in_channels[i+1]))\n",
    "        \n",
    "    def forward(self, agg_latent_input):\n",
    "        \n",
    "        for layer in self.decoder:\n",
    "            agg_latent_input = layer(agg_latent_input)\n",
    "            agg_latent_input = self.relu(agg_latent_input)\n",
    "        \n",
    "        out = agg_latent_input\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "567158e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# embedding_size = [16, 32, 10, 8, 6]\n",
    "# input_size = [50, 2, 24]\n",
    "# hidden_size = [16, 32, 64, 128]\n",
    "# output_size = [112, 2]\n",
    "\n",
    "# class ConcatLayer(nn.Module):\n",
    "#     def __init__(self, num_inputs):\n",
    "#         super().__init__()\n",
    "#         self.num_inputs = num_inputs\n",
    "        \n",
    "#     def forward(self, *inputs):\n",
    "#         squeezed_inputs = [torch.squeeze(x, dim=0) for x in inputs]\n",
    "#         return torch.cat(squeezed_inputs, dim=-1)\n",
    "\n",
    "# models = {\n",
    "#     \"sales_domain\": nn.ModuleList([\n",
    "#                     nn.Embedding(num_embeddings=num_users, embedding_dim=embedding_size[0]),\n",
    "#                     nn.Embedding(num_embeddings=num_items, embedding_dim=embedding_size[1]),\n",
    "#                     ConcatLayer(num_inputs=3),\n",
    "#                     nn.Sequential(\n",
    "#                         nn.Linear(in_features=input_size[0], out_features=hidden_size[3], bias=True),\n",
    "#                         nn.LeakyReLU(),\n",
    "#                         nn.Linear(in_features=hidden_size[3], out_features=hidden_size[2], bias=True),\n",
    "#                         nn.LeakyReLU()\n",
    "#                     )\n",
    "#     ]),\n",
    "#     \"customer_domain\": nn.Sequential(\n",
    "#                        nn.Linear(in_features=input_size[1], out_features=hidden_size[1], bias=True),\n",
    "#                        nn.LeakyReLU(),\n",
    "#                        nn.Linear(in_features=hidden_size[1], out_features=hidden_size[0], bias=True),\n",
    "#                        nn.LeakyReLU()\n",
    "    \n",
    "#     ),\n",
    "#     \"product_domain\": nn.ModuleList([\n",
    "#                       nn.Embedding(num_embeddings=num_product_groups, embedding_dim=embedding_size[2]),\n",
    "#                       nn.Embedding(num_embeddings=num_color_groups, embedding_dim=embedding_size[3]),\n",
    "#                       nn.Embedding(num_embeddings=num_index_name, embedding_dim=embedding_size[4]),\n",
    "#                       ConcatLayer(num_inputs=3),\n",
    "#                       nn.Sequential(\n",
    "#                           nn.Linear(in_features=input_size[2], out_features=hidden_size[2], bias=True),\n",
    "#                           nn.LeakyReLU(),\n",
    "#                           nn.Linear(in_features=hidden_size[2], out_features=hidden_size[1], bias=True),\n",
    "#                           nn.LeakyReLU()\n",
    "#                       )\n",
    "#     ]),\n",
    "#     \"server\": nn.Sequential(\n",
    "#               nn.Linear(in_features=output_size[0], out_features=hidden_size[2], bias=True),\n",
    "#               nn.LeakyReLU(),\n",
    "#               nn.Linear(in_features=hidden_size[2], out_features=hidden_size[0], bias=True),\n",
    "#               nn.LeakyReLU(),\n",
    "#               nn.Linear(in_features=hidden_size[0], out_features=output_size[1], bias=True),\n",
    "#     )\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "743c90c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_users: 44\n",
      "num_items: 1355\n",
      "num_product_groups: 9\n",
      "num_color_groups: 44\n"
     ]
    }
   ],
   "source": [
    "# set up parameters for model\n",
    "num_users = len(hm_data.customer_id.unique())\n",
    "print(\"num_users:\", num_users)\n",
    "num_items = len(all_products_id)\n",
    "print(\"num_items:\", num_items)\n",
    "num_product_groups = len(hm_data.product_group_name.unique())\n",
    "print(\"num_product_groups:\", num_product_groups)\n",
    "num_color_groups = len(hm_data.colour_group_name.unique())\n",
    "print(\"num_color_groups:\", num_color_groups)\n",
    "num_index_name = len(hm_data.index_name.unique())\n",
    "\n",
    "models = {\n",
    "    \"sales_domain\": SalesNN(num_users=num_users, num_items=num_items),\n",
    "    \"customer_domain\": CustomersNN(),\n",
    "    \"product_domain\": ProductsNN(num_product_groups=num_product_groups, num_color_groups=num_color_groups, num_index_name=num_index_name),\n",
    "    \"server\": GovernanceNN(),\n",
    "}\n",
    "\n",
    "# set up optimizer for clients' model\n",
    "optimizers = [\n",
    "    optim.SGD(models[location.id].parameters(), lr=0.05)\n",
    "    for location in model_locations\n",
    "]\n",
    "\n",
    "for location in model_locations:\n",
    "    models[location.id].send(location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "dca90398",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(data_pointer, models, data_owners, server):\n",
    "    \n",
    "    # receive output from each clients\n",
    "    client_output = {}\n",
    "    \n",
    "    # aggregated client output for server side\n",
    "    remote_output = []\n",
    "    \n",
    "    for owner in data_owners:\n",
    "        if owner.id == \"sales_domain\":\n",
    "            sales_part_ptr = models[owner.id](data_pointer[owner.id][0], data_pointer[owner.id][1], data_pointer[owner.id][2], data_pointer[owner.id][3])\n",
    "            \n",
    "            print(sales_part_ptr.get())\n",
    "            print(sales_part_ptr.get().size())\n",
    "            print(\"TEST\")\n",
    "            \n",
    "            client_poutput[owner.id] = models[owner.id][3](concat_part_ptr)\n",
    "            remote_output.append(\n",
    "                client_output[owner.id].move(server)\n",
    "            )\n",
    "        elif owner.id == \"customer_domain\":\n",
    "            client_output[owner.id] = models[owner.id](data_pointer[owner.id])\n",
    "            remote_output.append(\n",
    "                client_output[owner.id].move(server)\n",
    "            )\n",
    "        elif owner.id == \"product_domain\":\n",
    "            part_1 = models[owner.id](data_pointer[owner.id][0])\n",
    "            part_2 = models[owner.id](data_pointer[owner.id][1])\n",
    "            part_3 = models[owner.id](data_pointer[owner.id][2])\n",
    "            concat_part_ptr = models[owner.id][3](part_1, part_2, part_3)\n",
    "            client_output[owner.id] = models[owner.id][3](concat_part_ptr)\n",
    "            remote_output.append(\n",
    "                client_output[owner.id].move(server)\n",
    "            )\n",
    "    \n",
    "def train(data_pointer, label, data_owners, models, optmizers, server):\n",
    "    for opt in optimizers:\n",
    "        opt.zero_grad()\n",
    "    \n",
    "    pred = predict(data_pointer, models, data_owners, server)\n",
    "    acc = binary_acc(pred, label)\n",
    "    \n",
    "    # loss function\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    loss = loss_fn(pred, label)\n",
    "    loss.backward()\n",
    "    \n",
    "    for opt in optimizers:\n",
    "        opt.step()\n",
    "    \n",
    "    return loss.detach().get(), acc\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "91ce3ee7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 4.9529e-01,  6.2474e-01, -8.9927e-01,  ...,  1.2804e+00,\n",
      "          3.2604e-01,  4.5298e-01],\n",
      "        [-1.5664e+00,  1.6941e+00, -2.0681e-03,  ..., -1.9709e+00,\n",
      "         -1.0262e+00,  2.1196e+00],\n",
      "        [ 4.9529e-01,  6.2474e-01, -8.9927e-01,  ..., -9.1416e-01,\n",
      "          1.9485e-01, -1.1253e+00],\n",
      "        ...,\n",
      "        [-8.7036e-01, -1.2154e+00,  9.0904e-01,  ...,  4.1737e-01,\n",
      "         -3.9016e-01, -4.2336e-01],\n",
      "        [ 6.1625e-01,  6.6836e-01,  8.5924e-02,  ..., -9.1518e-01,\n",
      "         -7.8924e-01,  5.0368e-01],\n",
      "        [ 8.0404e-01, -7.6087e-01, -6.6247e-01,  ...,  1.0041e+00,\n",
      "         -1.5550e-01,  1.3555e+00]], grad_fn=<CatBackward>)\n",
      "torch.Size([64, 48])\n",
      "TEST\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "Dimension out of range (expected to be in range of [-1, 0], but got 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPureFrameworkTensorFoundError\u001b[0m             Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/envs/pyvertical-dev/lib/python3.7/site-packages/syft/frameworks/torch/tensors/interpreters/native.py\u001b[0m in \u001b[0;36mhandle_func_command\u001b[0;34m(cls, command)\u001b[0m\n\u001b[1;32m    336\u001b[0m             new_args, new_kwargs, new_type, args_type = hook_args.unwrap_args_from_function(\n\u001b[0;32m--> 337\u001b[0;31m                 \u001b[0mcmd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_args_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    338\u001b[0m             )\n",
      "\u001b[0;32m~/anaconda3/envs/pyvertical-dev/lib/python3.7/site-packages/syft/generic/frameworks/hook/hook_args.py\u001b[0m in \u001b[0;36munwrap_args_from_function\u001b[0;34m(attr, args_, kwargs_, return_args_type)\u001b[0m\n\u001b[1;32m    166\u001b[0m         \u001b[0;31m# Run it\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 167\u001b[0;31m         \u001b[0mnew_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0margs_hook_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    168\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pyvertical-dev/lib/python3.7/site-packages/syft/generic/frameworks/hook/hook_args.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    355\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 356\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlambdas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    357\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pyvertical-dev/lib/python3.7/site-packages/syft/generic/frameworks/hook/hook_args.py\u001b[0m in \u001b[0;36mthree_fold\u001b[0;34m(lambdas, args_, **kwargs)\u001b[0m\n\u001b[1;32m    534\u001b[0m         \u001b[0mlambdas\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 535\u001b[0;31m         \u001b[0mlambdas\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    536\u001b[0m         \u001b[0mlambdas\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pyvertical-dev/lib/python3.7/site-packages/syft/generic/frameworks/hook/hook_args.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(i)\u001b[0m\n\u001b[1;32m    330\u001b[0m         \u001b[0;31m# Last if not, rule is probably == 1 so use type to return the right transformation.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 331\u001b[0;31m         \u001b[0;32melse\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mforward_func\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    332\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrules\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# And do this for all the args / rules provided\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pyvertical-dev/lib/python3.7/site-packages/syft/frameworks/torch/hook/hook_args.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(i)\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"child\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m     \u001b[0;32melse\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0m_\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mthrow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPureFrameworkTensorFoundError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m     \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mParameter\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchild\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pyvertical-dev/lib/python3.7/site-packages/syft/frameworks/torch/hook/hook_args.py\u001b[0m in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"child\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m     \u001b[0;32melse\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0m_\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mthrow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPureFrameworkTensorFoundError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m     \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mParameter\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchild\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mPureFrameworkTensorFoundError\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_265592/1206543260.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mserver\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0macc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_ptr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_owners\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mserver\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mepoch_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_265592/3209916559.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(data_pointer, label, data_owners, models, optmizers, server)\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m     \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_pointer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_owners\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mserver\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m     \u001b[0macc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbinary_acc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_265592/3209916559.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(data_pointer, models, data_owners, server)\u001b[0m\n\u001b[1;32m     17\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"TEST\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m             \u001b[0mclient_poutput\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mowner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mowner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconcat_part_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m             remote_output.append(\n\u001b[1;32m     21\u001b[0m                 \u001b[0mclient_output\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mowner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmove\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mserver\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pyvertical-dev/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pyvertical-dev/lib/python3.7/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     98\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    101\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pyvertical-dev/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pyvertical-dev/lib/python3.7/site-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pyvertical-dev/lib/python3.7/site-packages/syft/generic/frameworks/hook/hook.py\u001b[0m in \u001b[0;36moverloaded_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    333\u001b[0m                 \u001b[0mhandle_func_command\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msyft\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframework\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle_func_command\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    334\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 335\u001b[0;31m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhandle_func_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    336\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    337\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pyvertical-dev/lib/python3.7/site-packages/syft/frameworks/torch/tensors/interpreters/native.py\u001b[0m in \u001b[0;36mhandle_func_command\u001b[0;34m(cls, command)\u001b[0m\n\u001b[1;32m    378\u001b[0m             \u001b[0;31m# in the execute_command function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    379\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 380\u001b[0;31m                 \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcmd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    381\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    382\u001b[0m                 \u001b[0;31m# Change the library path to avoid errors on layers like AvgPooling\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pyvertical-dev/lib/python3.7/site-packages/syft/frameworks/torch/tensors/interpreters/native.py\u001b[0m in \u001b[0;36m_get_response\u001b[0;34m(cmd, args_, kwargs_)\u001b[0m\n\u001b[1;32m    412\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    413\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 414\u001b[0;31m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcommand_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    415\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    416\u001b[0m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcommand_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pyvertical-dev/lib/python3.7/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m   1368\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mbias\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1369\u001b[0m         \u001b[0;31m# fused op is marginally faster\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1370\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1371\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1372\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pyvertical-dev/lib/python3.7/site-packages/syft/generic/frameworks/hook/hook.py\u001b[0m in \u001b[0;36moverloaded_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    333\u001b[0m                 \u001b[0mhandle_func_command\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msyft\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframework\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle_func_command\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    334\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 335\u001b[0;31m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhandle_func_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    336\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    337\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pyvertical-dev/lib/python3.7/site-packages/syft/frameworks/torch/tensors/interpreters/native.py\u001b[0m in \u001b[0;36mhandle_func_command\u001b[0;34m(cls, command)\u001b[0m\n\u001b[1;32m    378\u001b[0m             \u001b[0;31m# in the execute_command function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    379\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 380\u001b[0;31m                 \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcmd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    381\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    382\u001b[0m                 \u001b[0;31m# Change the library path to avoid errors on layers like AvgPooling\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pyvertical-dev/lib/python3.7/site-packages/syft/frameworks/torch/tensors/interpreters/native.py\u001b[0m in \u001b[0;36m_get_response\u001b[0;34m(cmd, args_, kwargs_)\u001b[0m\n\u001b[1;32m    412\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    413\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 414\u001b[0;31m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcommand_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    415\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    416\u001b[0m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcommand_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: Dimension out of range (expected to be in range of [-1, 0], but got 1)"
     ]
    }
   ],
   "source": [
    "# model training\n",
    "epochs = 20\n",
    "\n",
    "for i in range(epochs):\n",
    "    epoch_loss = 0.0\n",
    "    epoch_acc = 0.0\n",
    "    \n",
    "    #  iterate over each datapoints \n",
    "    for data_ptr, label in distributed_trainloader:\n",
    "        \n",
    "        # send labels to server's location for training\n",
    "        label = label.send(server)\n",
    "        \n",
    "        loss, acc = train(data_ptr, label, data_owners, models, optimizers, server)\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc += acc.item()\n",
    "    if cur_acc > best_acc:\n",
    "        best_acc = cur_acc\n",
    "        # torch.save(model.state_dict(), 'best_model.pt')\n",
    "    print(f'Epoch {e+0:03}: | Loss: {epoch_loss/len(trainloader):.6f} | Acc: {epoch_acc/len(trainloader):.4f}')\n",
    "\n",
    "print(f'\\nBest Accuracy: {best_acc:.3f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
